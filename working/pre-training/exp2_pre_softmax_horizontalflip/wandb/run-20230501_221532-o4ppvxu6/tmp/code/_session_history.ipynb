{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454862af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "cmap = mpl.cm.get_cmap('coolwarm')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import wandb\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from timm.scheduler import CosineLRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e47cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import CFG\n",
    "from pytorch_model import BirdCLEF23Net\n",
    "from pytorch_wav2logmel import Wav2Logmel\n",
    "import pytorch_modeler as modeler\n",
    "import pytorch_preprocessing as prep\n",
    "import common as com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f723fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeler.set_seed(CFG.seed)\n",
    "# setting\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print('Debug :', CFG.debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1650824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get the API key from Kaggle secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"WANDB\")\n",
    "    # Login to wandb with the API key\n",
    "    wandb.login(key=api_key)\n",
    "    print('kaggle notebook mode')\n",
    "except:\n",
    "    key_path = '/kaggle/input/wandb_key.txt'\n",
    "    p = Path(key_path)\n",
    "    api_key = p.read_text()\n",
    "    wandb.login(key=api_key)\n",
    "    print('local mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "808acfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを設定\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在時刻を取得し、日本時間に変換\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 現在時刻を文字列に変換\n",
    "now_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(now_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4c8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "def wandb_init(fold):\n",
    "    config = {k: v for k, v in dict(vars(CFG)).items() if '__' not in k}\n",
    "    config.update({\"fold\": int(fold)})\n",
    "    yaml.dump(config, open(f'./config fold-{fold}.yaml', 'w'), )\n",
    "    config = yaml.load(open(f'./config fold-{fold}.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "    run = wandb.init(project=\"birdclef-2023-public\",\n",
    "                     name=f\"fold-{fold}|dim-{CFG.img_size[1]}x{CFG.img_size[0]}|model-{CFG.model_name}|{now_str}\",\n",
    "                     config=config,\n",
    "                     group=CFG.comment,\n",
    "                     save_code=True, )\n",
    "    return run\n",
    "\n",
    "\n",
    "def log_wandb(valid_df):\n",
    "    save_df = valid_df.query(\"miss==True\")\n",
    "    save_df.loc[:, 'pred_name'] = save_df.pred.map(CFG.label2name2)\n",
    "    save_df.loc[:, 'target_name'] = save_df.target.map(CFG.label2name2)\n",
    "    if CFG.debug:\n",
    "        save_df = save_df.iloc[:CFG.batch_size * CFG.valid_bs]\n",
    "    noimg_cols = [*CFG.tab_cols, 'target', 'pred', 'target_name', 'pred_name']\n",
    "    save_df = save_df.loc[:, noimg_cols]\n",
    "\n",
    "#    data = []\n",
    "#   for idx, row in tqdm(save_df.iterrows(), total=len(save_df), desc='wandb ', position=0, leave=True):\n",
    "#        filepath = row.\n",
    "#       audio, sr = librosa.load(filepath, sr=None)\n",
    "#        data += [[*row.tolist(), wandb.Audio(audio, caption=row.filename, sample_rate=sr)]]\n",
    "    #wandb_table = wandb.Table(data=data, columns=[*noimg_cols, 'audio'])\n",
    "    wandb.log({'best': scores,\n",
    " #              'table': wandb_table,\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c4b13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.io.formats.style.Styler at 0x7f440dc3aed0>"
     ]
    }
   ],
   "source": [
    "# df_23 = pd.read_csv(f'{CFG.BASE_PATH}/train_metadata.csv')\n",
    "# filename = df_23.filename.str.replace('.ogg', '.wav')\n",
    "# df_23['filepath'] = CFG.BASE_PATH + '/train_audio_wav/' + filename\n",
    "# df_23['target'] = df_23.primary_label.map(CFG.name2label)\n",
    "# df_23['birdclef'] = '23'\n",
    "# df_23['filename'] = df_23.filepath.map(lambda x: x.split('/')[-1])\n",
    "# df_23['xc_id'] = df_23.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\n",
    "# df_23.head(2)\n",
    "\n",
    "# # Display rwos\n",
    "# print(\"# Samples in BirdCLEF 23: {:,}\".format(len(df_23)))\n",
    "# df_23.head(2).style.set_caption(\"BirdCLEF - 23\").set_table_styles([{\n",
    "#     'selector': 'caption',\n",
    "#     'props': [\n",
    "#         ('color', 'blue'),\n",
    "#         ('font-size', '16px')\n",
    "#     ]\n",
    "# }])\n",
    "df_23 = pd.read_csv(f'{CFG.BASE_PATH3}/train_metadata.csv')\n",
    "df_23['filepath'] = CFG.BASE_PATH3 + '/train_audio/' + df_23.filename\n",
    "df_23['target'] = df_23.primary_label.map(CFG.name2label)\n",
    "df_23['birdclef'] = '23'\n",
    "df_23['filename'] = df_23.filepath.map(lambda x: x.split('/')[-1])\n",
    "df_23['xc_id'] = df_23.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\n",
    "#assert tf.io.gfile.exists(df_23.filepath.iloc[0])\n",
    "\n",
    "# Display rwos\n",
    "print(\"# Samples in BirdCLEF 23: {:,}\".format(len(df_23)))\n",
    "df_23.head(2).style.set_caption(\"BirdCLEF - 23\").set_table_styles([{\n",
    "    'selector': 'caption',\n",
    "    'props': [\n",
    "        ('color', 'blue'),\n",
    "        ('font-size', '16px')\n",
    "    ]\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1d9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BirdCLEF-2020\n",
    "df_20 = pd.read_csv(f'{CFG.BASE_PATH0}/train.csv')\n",
    "df_20['primary_label'] = df_20['ebird_code']\n",
    "df_20['filepath'] = CFG.BASE_PATH0 + '/train_audio/' + df_20.primary_label + '/' + df_20.filename\n",
    "df_20['scientific_name'] = df_20['sci_name']\n",
    "df_20['common_name'] = df_20['species']\n",
    "df_20['target'] = df_20.primary_label.map(CFG.name2label2)\n",
    "df_20['birdclef'] = '20'\n",
    "#assert tf.io.gfile.exists(df_20.filepath.iloc[0])\n",
    "\n",
    "# Xeno-Canto Extend by @vopani\n",
    "df_xam = pd.read_csv(f'{CFG.BASE_PATH4}/train_extended.csv')\n",
    "df_xam['filepath'] = CFG.BASE_PATH4 + '/A-M/' + df_xam.ebird_code + '/' + df_xam.filename\n",
    "df_xnz = pd.read_csv(f'{CFG.BASE_PATH5}/train_extended.csv')\n",
    "df_xnz['filepath'] = CFG.BASE_PATH5 + '/N-Z/' + df_xnz.ebird_code + '/' + df_xnz.filename\n",
    "df_xc = pd.concat([df_xam, df_xnz], axis=0, ignore_index=True)\n",
    "df_xc['primary_label'] = df_xc['ebird_code']\n",
    "df_xc['scientific_name'] = df_xc['sci_name']\n",
    "df_xc['common_name'] = df_xc['species']\n",
    "df_xc['target'] = df_xc.primary_label.map(CFG.name2label2)\n",
    "df_xc['birdclef'] = 'xc'\n",
    "#assert tf.io.gfile.exists(df_xc.filepath.iloc[0])\n",
    "\n",
    "# BirdCLEF-2021\n",
    "df_21 = pd.read_csv(f'{CFG.BASE_PATH1}/train_metadata.csv')\n",
    "df_21['filepath'] = CFG.BASE_PATH1 + '/train_short_audio/' + df_21.primary_label + '/' + df_21.filename\n",
    "df_21['target'] = df_21.primary_label.map(CFG.name2label2)\n",
    "df_21['birdclef'] = '21'\n",
    "corrupt_paths = [f'{CFG.BASE_PATH1}/train_short_audio/houwre/XC590621.ogg',\n",
    "                 f'{CFG.BASE_PATH1}/train_short_audio/cogdov/XC579430.ogg']\n",
    "df_21 = df_21[~df_21.filepath.isin(corrupt_paths)] # remove all zero audios\n",
    "#assert tf.io.gfile.exists(df_21.filepath.iloc[0])\n",
    "\n",
    "# BirdCLEF-2022\n",
    "df_22 = pd.read_csv(f'{CFG.BASE_PATH2}/train_metadata.csv')\n",
    "df_22['filepath'] = CFG.BASE_PATH2 + '/train_audio/' + df_22.filename\n",
    "df_22['target'] = df_22.primary_label.map(CFG.name2label2)\n",
    "df_22['birdclef'] = '22'\n",
    "#assert tf.io.gfile.exists(df_22.filepath.iloc[0])\n",
    "\n",
    "# Merge 2021 and 2022 for pretraining\n",
    "df_pre = pd.concat([df_20, df_21, df_22, df_xc], axis=0, ignore_index=True)\n",
    "df_pre['filename'] = df_pre.filepath.map(lambda x: x.split('/')[-1])\n",
    "df_pre['xc_id'] = df_pre.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\n",
    "nodup_idx = df_pre[['xc_id','primary_label','author']].drop_duplicates().index\n",
    "df_pre = df_pre.loc[nodup_idx].reset_index(drop=True)\n",
    "\n",
    "# # Remove duplicates\n",
    "df_pre = df_pre[~df_pre.xc_id.isin(df_23.xc_id)].reset_index(drop=True)\n",
    "corrupt_mp3s = json.load(open('/kaggle/input/birdclef-2023-dataset/corrupt_mp3_files.json','r'))\n",
    "corrupt_mp3s = [path.replace('/kaggle/input','/kaggle/input/birdclef-2023-dataset') for path in corrupt_mp3s]\n",
    "df_pre = df_pre[~df_pre.filepath.isin(corrupt_mp3s)]\n",
    "df_pre = df_pre[['filename','filepath','primary_label','secondary_labels',\n",
    "                 'rating','author','file_type','xc_id','scientific_name',\n",
    "                'common_name','target','birdclef','bird_seen']]\n",
    "# Display rows\n",
    "print(\"# Samples for Pre-Training: {:,}\".format(len(df_pre)))\n",
    "df_pre.head(2).style.set_caption(\"Pre-Training Data\").set_table_styles([{\n",
    "    'selector': 'caption',\n",
    "    'props': [\n",
    "        ('color', 'blue'),\n",
    "        ('font-size', '16px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "# Show distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "df_pre.birdclef.value_counts().plot.bar(color=[cmap(0.0),cmap(0.25), cmap(0.65), cmap(0.9)])\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Dataset distribution for Pre-Training\")\n",
    "plt.show()\n",
    "\n",
    "# サンプル数が合わない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a1abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre['filepath']=df_pre['filepath'].str.replace('train_audio', 'train_audio_mono_wav')\n",
    "df_pre['filepath']=df_pre['filepath'].str.replace('train_short_audio', 'train_short_audio_mono_wav')\n",
    "df_pre['filepath']=df_pre['filepath'].str.replace('A-M', 'A-M_wav')\n",
    "df_pre['filepath']=df_pre['filepath'].str.replace('mp3', 'wav')\n",
    "df_pre['filepath']=df_pre['filepath'].str.replace('ogg', 'wav')\n",
    "df_pre=df_pre.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60471bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pre.filepath.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9987ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import required packages\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Initialize the StratifiedKFold object with 5 splits and shuffle the data\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "# # Reset the index of the dataframe\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "# # Create a new column in the dataframe to store the fold number for each row\n",
    "# df[\"fold\"] = -1\n",
    "\n",
    "# # Iterate over the folds and assign the corresponding fold number to each row in the dataframe\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['primary_label'])):\n",
    "#     df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "# Import required packages\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize the StratifiedKFold object with 5 splits and shuffle the data\n",
    "skf1 = StratifiedKFold(n_splits=25, shuffle=True, random_state=CFG.seed)\n",
    "skf2 = StratifiedKFold(n_splits=CFG.num_fold, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "# Reset the index of the dataframe\n",
    "df_pre = df_pre.reset_index(drop=True)\n",
    "df_23 = df_23.reset_index(drop=True)\n",
    "\n",
    "# Create a new column in the dataframe to store the fold number for each row\n",
    "df_pre[\"fold\"] = -1\n",
    "df_23[\"fold\"] = -1\n",
    "\n",
    "# BirdCLEF - 21 & 22\n",
    "for fold, (train_idx, val_idx) in enumerate(skf1.split(df_pre, df_pre['primary_label'])):\n",
    "    df_pre.loc[val_idx, 'fold'] = fold\n",
    "    \n",
    "# IBirdCLEF - 23\n",
    "for fold, (train_idx, val_idx) in enumerate(skf2.split(df_23, df_23['primary_label'])):\n",
    "    df_23.loc[val_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9695d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch(batch, row=3, col=3, label2name=None,):\n",
    "    \"\"\"Plot one batch data\"\"\"\n",
    "    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "        audios, tars = batch\n",
    "    else:\n",
    "        audios = batch\n",
    "        tars = None\n",
    "    plt.figure(figsize=(col*5, row*3))\n",
    "    for idx in range(row*col):\n",
    "        ax = plt.subplot(row, col, idx+1)\n",
    "        plt.plot(audios[idx].numpy(), color=cmap(0.1))\n",
    "        if tars is not None:\n",
    "            label = tars[idx].numpy().argmax()\n",
    "            name = label2name[label]\n",
    "            plt.title(name)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_history(history):\n",
    "    \"\"\"Plot trainign history, credit: @cdeotte\"\"\"\n",
    "    epochs = len(history.history['auc'])\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(np.arange(epochs),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n",
    "    plt.plot(np.arange(epochs),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n",
    "    x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n",
    "    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n",
    "    plt.ylabel('AUC (PR)',size=14); plt.xlabel('Epoch',size=14)\n",
    "    plt.legend(loc=2)\n",
    "    plt2 = plt.gca().twinx()\n",
    "    plt2.plot(np.arange(epochs),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n",
    "    plt2.plot(np.arange(epochs),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n",
    "    x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n",
    "    ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n",
    "    plt.ylabel('Loss',size=14)\n",
    "    plt.title('Fold %i - Training Plot'%(fold+1),size=18)\n",
    "    plt.legend(loc=3)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21218932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def gc_collect():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91e7cc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/pre-training/exp2_pre_softmax_horizontalflip/wandb/run-20230501_221532-o4ppvxu6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public/runs/o4ppvxu6\" target=\"_blank\">fold-0|dim-313x224|model-tf_efficientnet_b1_ns|2023-05-02 07:15:28</a></strong> to <a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "oof_pred = []; oof_true = []; oof_val = []; oof_ids = []; oof_folds = [] \n",
    "# Configurations\n",
    "num_classes = CFG.num_classes2\n",
    "df = df_pre.copy()\n",
    "fold = 0\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Initialize Weights and Biases\n",
    "if CFG.wandb:\n",
    "    run = wandb_init(fold)\n",
    "\n",
    "# Compute batch size and number of samples to drop\n",
    "infer_bs = CFG.valid_bs\n",
    "drop_remainder = CFG.drop_remainder\n",
    "\n",
    "# Split dataset with cv filter\n",
    "if CFG.cv_filter:\n",
    "    df = com.filter_data(df, thr=5)\n",
    "    train_df = df.query(\"fold!=@fold | ~cv\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold & cv\").reset_index(drop=True)\n",
    "else:\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "\n",
    "# Upsample train data\n",
    "train_df = com.upsample_data(train_df, thr=50)\n",
    "train_df = com.downsample_data(train_df, thr=500)\n",
    "\n",
    "# Get file paths and labels\n",
    "train_paths = train_df.filepath.values; train_labels = train_df.target.values\n",
    "valid_paths = valid_df.filepath.values; valid_labels = valid_df.target.values\n",
    "\n",
    "# Shuffle the file paths and labels\n",
    "index = np.arange(len(train_paths))\n",
    "np.random.shuffle(index)\n",
    "train_paths  = train_paths[index]\n",
    "train_labels = train_labels[index]\n",
    "\n",
    "# wav\n",
    "train_ftype = list(map(lambda x: '.wav' in x, train_paths))\n",
    "valid_ftype = list(map(lambda x: '.wav' in x, valid_paths))\n",
    "\n",
    "# Compute the number of training and validation samples\n",
    "num_train = len(train_paths); num_valid = len(valid_paths)\n",
    "    \n",
    "# Log the number of training and validation samples if Weights and Biases is being used\n",
    "if CFG.wandb:\n",
    "    wandb.log({'num_train':num_train,\n",
    "                'num_valid':num_valid})\n",
    "    \n",
    "# Build the training and validation datasets\n",
    "# For debugging\n",
    "if CFG.debug:\n",
    "    min_samples = CFG.batch_size\n",
    "    train_ds = prep.BirdDataset(train_df.iloc[:min_samples], is_train=True)\n",
    "    valid_ds = prep.BirdDataset(valid_df, is_train=False)\n",
    "else:\n",
    "    train_ds = prep.BirdDataset(train_df, is_train=True)\n",
    "    valid_ds = prep.BirdDataset(valid_df, is_train=False)\n",
    "# dataloader\n",
    "train_dataloader, val_dataloader = modeler.make_dataloder(train_ds, valid_ds)\n",
    "\n",
    "wav_to_logmel = Wav2Logmel()\n",
    "# Clear the session and build the model\n",
    "model = BirdCLEF23Net(num_classes=num_classes)\n",
    "# Load birdclef pretrained weights\n",
    "if CFG.pretrain == True:\n",
    "    model.load_state_dict(torch.load(CFG.pretrained_model_path), strict=False)\n",
    "model.to(device)\n",
    "wav_to_logmel.to(device)\n",
    "\n",
    "print('#' * 25)\n",
    "print('#### Training')\n",
    "print('#### Fold: %i | Image Size: (%i, %i) | Model: %s | Batch Size: %i | Scheduler: %s' %\n",
    "    (fold + 1, *CFG.img_size, CFG.model_name, CFG.batch_size, CFG.scheduler))\n",
    "print('#### Num Train: {:,} | Num Valid: {:,}'.format(len(train_paths), len(valid_paths)))\n",
    "\n",
    "optimizer = com.get_optimizer(model)\n",
    "# TODO com.get_scheduler\n",
    "scheduler = CosineLRScheduler(optimizer, t_initial=CFG.epochs, lr_min=CFG.lr_min, \n",
    "                                warmup_t=CFG.warmup_t, warmup_lr_init=CFG.warmup_lr_init, warmup_prefix=True)\n",
    "criterion = com.get_criterion()\n",
    "\n",
    "best_score = -1\n",
    "best_epoch = -1\n",
    "\n",
    "for epoch in range(2 if CFG.debug else CFG.epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (inputs, sample_info) in enumerate(tqdm(train_dataloader)):\n",
    "        inputs, targets = inputs.to(device), sample_info['target'].to(device)\n",
    "        targets = F.one_hot(targets, num_classes=num_classes).float()\n",
    "        optimizer.zero_grad()\n",
    "        logmel = wav_to_logmel(inputs)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs, mix_targets = model(logmel, targets)\n",
    "            loss = criterion(outputs, mix_targets)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if np.isinf(loss.item()) or np.isnan(loss.item()):\n",
    "            print(f'Bad loss, skipping the batch {batch_idx}')\n",
    "            del loss, outputs, mix_targets\n",
    "            gc_collect()\n",
    "            continue\n",
    "        epoch_loss += loss.item()\n",
    "        # wandb logger (Train loss)\n",
    "        run.log({'loss': loss.item()})\n",
    "    scheduler.step(epoch+1)\n",
    "    \n",
    "    # gc\n",
    "    # del logmel\n",
    "    # torch.cuda.empty_cache()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, sample_info in tqdm(val_dataloader):\n",
    "            inputs, targets = inputs.to(device), sample_info['target'].to(device)\n",
    "            targets = F.one_hot(targets, num_classes=num_classes).float()\n",
    "            logmel = wav_to_logmel(inputs)\n",
    "            outputs = model(logmel)\n",
    "            loss = criterion(outputs, targets)\n",
    "            outputs = torch.softmax(outputs, dim=1)#torch.softmax(outputs, dim=1)\n",
    "            #outputs = torch.softmax(outputs, dim=1)\n",
    "            val_loss += loss.item()\n",
    "            val_preds.append(outputs.detach().cpu().numpy())\n",
    "            val_true.append(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_preds = np.vstack(val_preds)\n",
    "    val_true = np.vstack(val_true)\n",
    "    # Metrics\n",
    "    val_score = com.padded_cmap(val_true, val_preds)\n",
    "    # Checkpoint\n",
    "    if val_score > best_score:\n",
    "        best_score = val_score\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), f'fold-{fold}.pth')\n",
    "        art = wandb.Artifact(\"birdclef-2023\", type=\"model\")\n",
    "        art.add_file(f'fold-{fold}.pth')\n",
    "        run.log_artifact(art)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1} | Train Loss: {epoch_loss / len(train_dataloader)} | '\n",
    "        f'Val Loss: {val_loss / len(val_dataloader)} | Val Padded_cmAP : {val_score}')\n",
    "    \n",
    "    # wandb logger\n",
    "    lr = scheduler.get_epoch_values(epoch)[0]\n",
    "    run.log({'train_loss': epoch_loss / len(train_dataloader),\n",
    "             'lr': lr,\n",
    "             'epoch': epoch+1,\n",
    "             'valid_loss': val_loss / len(val_dataloader),\n",
    "             'valid_padded_cmAP': val_score,})\n",
    "    \n",
    "    \n",
    "# Load best checkpoint\n",
    "print('# Loading best model')\n",
    "model.load_state_dict(torch.load(f'fold-{fold}.pth'))\n",
    "\n",
    "# Predict on the validation data for oof result\n",
    "print('# Infering OOF')\n",
    "model.eval()\n",
    "oof_pred_ = []\n",
    "with torch.no_grad():\n",
    "    for inputs, sample_info in tqdm(val_dataloader):\n",
    "        inputs, targets = inputs.to(device), sample_info['target'].to(device)\n",
    "        logmel = wav_to_logmel(inputs)\n",
    "        outputs = model(logmel)\n",
    "        outputs = torch.softmax(outputs, dim=1)\n",
    "        oof_pred_.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "oof_pred_ = np.concatenate(oof_pred_, axis=0)\n",
    "# oof_pred : 5\n",
    "oof_pred.append(oof_pred_)\n",
    "\n",
    "# Get ids and targets\n",
    "oof_true.append(valid_labels)\n",
    "oof_folds.append(np.ones_like(oof_true[-1], dtype='int8') * fold)\n",
    "oof_ids.append(valid_paths)\n",
    "\n",
    "# Save valid data prediction\n",
    "y_true = np.array(oof_true[-1])\n",
    "y_pred = np.argmax(oof_pred[-1], axis=-1)\n",
    "\n",
    "valid_df['pred'] = y_pred\n",
    "valid_df['miss'] = y_true != y_pred\n",
    "valid_df[CFG.class_names2] = oof_pred[-1].tolist()\n",
    "# Log the metrics\n",
    "scores = {}\n",
    "cmAP = com.padded_cmap(com.one_hot_encode(y_true), oof_pred[-1])\n",
    "oof_val.append(best_score)\n",
    "print('\\n>>> FOLD %i Padded_cmAP = %.3f' % (fold+1, cmAP))\n",
    "scores.update({'epoch': best_epoch,\n",
    "                'cmAP': cmAP,})\n",
    "# wandb logger \n",
    "run.log(scores)\n",
    "# Show training plot\n",
    "# if CFG.training_plot:\n",
    "#     plot_history(history)\n",
    "# Log metrics, media to wandb\n",
    "if CFG.wandb:\n",
    "    print('# WandB')\n",
    "    log_wandb(valid_df)\n",
    "    wandb.run.finish()\n",
    "    #display(ipd.IFrame(run.url, width=1080, height=720))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
