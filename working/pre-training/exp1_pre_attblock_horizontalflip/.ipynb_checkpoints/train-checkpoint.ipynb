{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imprements by https://www.kaggle.com/code/awsaf49/birdclef23-effnet-fsr-cutmixup-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impoert library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "cmap = mpl.cm.get_cmap('coolwarm')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import wandb\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from timm.scheduler import CosineLRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import CFG\n",
    "from pytorch_model import BirdCLEF23Net\n",
    "from pytorch_wav2logmel import Wav2Logmel\n",
    "import pytorch_modeler as modeler\n",
    "import pytorch_preprocessing as prep\n",
    "import common as com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Debug : True\n"
     ]
    }
   ],
   "source": [
    "modeler.set_seed(CFG.seed)\n",
    "# setting\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print('Debug :', CFG.debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhirokin1999\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local mode\n"
     ]
    }
   ],
   "source": [
    "# Try to get the API key from Kaggle secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"WANDB\")\n",
    "    # Login to wandb with the API key\n",
    "    wandb.login(key=api_key)\n",
    "    print('kaggle notebook mode')\n",
    "except:\n",
    "    key_path = '/kaggle/input/wandb_key.txt'\n",
    "    p = Path(key_path)\n",
    "    api_key = p.read_text()\n",
    "    wandb.login(key=api_key)\n",
    "    print('local mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-30 21:29:36\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを設定\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在時刻を取得し、日本時間に変換\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 現在時刻を文字列に変換\n",
    "now_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(now_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "def wandb_init(fold):\n",
    "    config = {k: v for k, v in dict(vars(CFG)).items() if '__' not in k}\n",
    "    config.update({\"fold\": int(fold)})\n",
    "    yaml.dump(config, open(f'./config fold-{fold}.yaml', 'w'), )\n",
    "    config = yaml.load(open(f'./config fold-{fold}.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "    run = wandb.init(project=\"birdclef-2023-public\",\n",
    "                     name=f\"fold-{fold}|dim-{CFG.img_size[1]}x{CFG.img_size[0]}|model-{CFG.model_name}|{now_str}\",\n",
    "                     config=config,\n",
    "                     group=CFG.comment,\n",
    "                     save_code=True, )\n",
    "    return run\n",
    "\n",
    "\n",
    "def log_wandb(valid_df):\n",
    "    save_df = valid_df.query(\"miss==True\")\n",
    "    save_df.loc[:, 'pred_name'] = save_df.pred.map(CFG.label2name)\n",
    "    save_df.loc[:, 'target_name'] = save_df.target.map(CFG.label2name)\n",
    "    if CFG.debug:\n",
    "        save_df = save_df.iloc[:CFG.batch_size * CFG.valid_bs]\n",
    "    noimg_cols = [*CFG.tab_cols, 'target', 'pred', 'target_name', 'pred_name']\n",
    "    save_df = save_df.loc[:, noimg_cols]\n",
    "\n",
    "    data = []\n",
    "    for idx, row in tqdm(save_df.iterrows(), total=len(save_df), desc='wandb ', position=0, leave=True):\n",
    "        filepath = '/kaggle/input/birdclef-2023/train_audio/' + row.filename\n",
    "        audio, sr = librosa.load(filepath, sr=None)\n",
    "        data += [[*row.tolist(), wandb.Audio(audio, caption=row.filename, sample_rate=sr)]]\n",
    "    wandb_table = wandb.Table(data=data, columns=[*noimg_cols, 'audio'])\n",
    "    wandb.log({'best': scores,\n",
    "               'table': wandb_table,\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Samples in BirdCLEF 23: 16,941\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a2308_ caption {\n",
       "  color: blue;\n",
       "  font-size: 16px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a2308_\">\n",
       "  <caption>BirdCLEF - 23</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >primary_label</th>\n",
       "      <th class=\"col_heading level0 col1\" >secondary_labels</th>\n",
       "      <th class=\"col_heading level0 col2\" >type</th>\n",
       "      <th class=\"col_heading level0 col3\" >latitude</th>\n",
       "      <th class=\"col_heading level0 col4\" >longitude</th>\n",
       "      <th class=\"col_heading level0 col5\" >scientific_name</th>\n",
       "      <th class=\"col_heading level0 col6\" >common_name</th>\n",
       "      <th class=\"col_heading level0 col7\" >author</th>\n",
       "      <th class=\"col_heading level0 col8\" >license</th>\n",
       "      <th class=\"col_heading level0 col9\" >rating</th>\n",
       "      <th class=\"col_heading level0 col10\" >url</th>\n",
       "      <th class=\"col_heading level0 col11\" >filename</th>\n",
       "      <th class=\"col_heading level0 col12\" >filepath</th>\n",
       "      <th class=\"col_heading level0 col13\" >target</th>\n",
       "      <th class=\"col_heading level0 col14\" >birdclef</th>\n",
       "      <th class=\"col_heading level0 col15\" >xc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a2308_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a2308_row0_col0\" class=\"data row0 col0\" >abethr1</td>\n",
       "      <td id=\"T_a2308_row0_col1\" class=\"data row0 col1\" >[]</td>\n",
       "      <td id=\"T_a2308_row0_col2\" class=\"data row0 col2\" >['song']</td>\n",
       "      <td id=\"T_a2308_row0_col3\" class=\"data row0 col3\" >4.390600</td>\n",
       "      <td id=\"T_a2308_row0_col4\" class=\"data row0 col4\" >38.278800</td>\n",
       "      <td id=\"T_a2308_row0_col5\" class=\"data row0 col5\" >Turdus tephronotus</td>\n",
       "      <td id=\"T_a2308_row0_col6\" class=\"data row0 col6\" >African Bare-eyed Thrush</td>\n",
       "      <td id=\"T_a2308_row0_col7\" class=\"data row0 col7\" >Rolf A. de By</td>\n",
       "      <td id=\"T_a2308_row0_col8\" class=\"data row0 col8\" >Creative Commons Attribution-NonCommercial-ShareAlike 3.0</td>\n",
       "      <td id=\"T_a2308_row0_col9\" class=\"data row0 col9\" >4.000000</td>\n",
       "      <td id=\"T_a2308_row0_col10\" class=\"data row0 col10\" >https://www.xeno-canto.org/128013</td>\n",
       "      <td id=\"T_a2308_row0_col11\" class=\"data row0 col11\" >XC128013.ogg</td>\n",
       "      <td id=\"T_a2308_row0_col12\" class=\"data row0 col12\" >/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg</td>\n",
       "      <td id=\"T_a2308_row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "      <td id=\"T_a2308_row0_col14\" class=\"data row0 col14\" >23</td>\n",
       "      <td id=\"T_a2308_row0_col15\" class=\"data row0 col15\" >XC128013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2308_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a2308_row1_col0\" class=\"data row1 col0\" >abethr1</td>\n",
       "      <td id=\"T_a2308_row1_col1\" class=\"data row1 col1\" >[]</td>\n",
       "      <td id=\"T_a2308_row1_col2\" class=\"data row1 col2\" >['call']</td>\n",
       "      <td id=\"T_a2308_row1_col3\" class=\"data row1 col3\" >-2.952400</td>\n",
       "      <td id=\"T_a2308_row1_col4\" class=\"data row1 col4\" >38.292100</td>\n",
       "      <td id=\"T_a2308_row1_col5\" class=\"data row1 col5\" >Turdus tephronotus</td>\n",
       "      <td id=\"T_a2308_row1_col6\" class=\"data row1 col6\" >African Bare-eyed Thrush</td>\n",
       "      <td id=\"T_a2308_row1_col7\" class=\"data row1 col7\" >James Bradley</td>\n",
       "      <td id=\"T_a2308_row1_col8\" class=\"data row1 col8\" >Creative Commons Attribution-NonCommercial-ShareAlike 4.0</td>\n",
       "      <td id=\"T_a2308_row1_col9\" class=\"data row1 col9\" >3.500000</td>\n",
       "      <td id=\"T_a2308_row1_col10\" class=\"data row1 col10\" >https://www.xeno-canto.org/363501</td>\n",
       "      <td id=\"T_a2308_row1_col11\" class=\"data row1 col11\" >XC363501.ogg</td>\n",
       "      <td id=\"T_a2308_row1_col12\" class=\"data row1 col12\" >/kaggle/input/birdclef-2023/train_audio/abethr1/XC363501.ogg</td>\n",
       "      <td id=\"T_a2308_row1_col13\" class=\"data row1 col13\" >0</td>\n",
       "      <td id=\"T_a2308_row1_col14\" class=\"data row1 col14\" >23</td>\n",
       "      <td id=\"T_a2308_row1_col15\" class=\"data row1 col15\" >XC363501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f859ba3c650>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_23 = pd.read_csv(f'{CFG.BASE_PATH}/train_metadata.csv')\n",
    "# filename = df_23.filename.str.replace('.ogg', '.wav')\n",
    "# df_23['filepath'] = CFG.BASE_PATH + '/train_audio_wav/' + filename\n",
    "# df_23['target'] = df_23.primary_label.map(CFG.name2label)\n",
    "# df_23['birdclef'] = '23'\n",
    "# df_23['filename'] = df_23.filepath.map(lambda x: x.split('/')[-1])\n",
    "# df_23['xc_id'] = df_23.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\n",
    "# df_23.head(2)\n",
    "\n",
    "# # Display rwos\n",
    "# print(\"# Samples in BirdCLEF 23: {:,}\".format(len(df_23)))\n",
    "# df_23.head(2).style.set_caption(\"BirdCLEF - 23\").set_table_styles([{\n",
    "#     'selector': 'caption',\n",
    "#     'props': [\n",
    "#         ('color', 'blue'),\n",
    "#         ('font-size', '16px')\n",
    "#     ]\n",
    "# }])\n",
    "df_23 = pd.read_csv(f'{CFG.BASE_PATH3}/train_metadata.csv')\n",
    "df_23['filepath'] = CFG.BASE_PATH3 + '/train_audio/' + df_23.filename\n",
    "df_23['target'] = df_23.primary_label.map(CFG.name2label)\n",
    "df_23['birdclef'] = '23'\n",
    "df_23['filename'] = df_23.filepath.map(lambda x: x.split('/')[-1])\n",
    "df_23['xc_id'] = df_23.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\n",
    "#assert tf.io.gfile.exists(df_23.filepath.iloc[0])\n",
    "\n",
    "# Display rwos\n",
    "print(\"# Samples in BirdCLEF 23: {:,}\".format(len(df_23)))\n",
    "df_23.head(2).style.set_caption(\"BirdCLEF - 23\").set_table_styles([{\n",
    "    'selector': 'caption',\n",
    "    'props': [\n",
    "        ('color', 'blue'),\n",
    "        ('font-size', '16px')\n",
    "    ]\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20, 21, 22, xeno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Samples for Pre-Training: 80,394\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BirdCLEF-2020\n",
    "df_20 = pd.read_csv(f'{CFG.BASE_PATH0}/train.csv')\n",
    "df_20['primary_label'] = df_20['ebird_code']\n",
    "df_20['filepath'] = CFG.BASE_PATH0 + '/train_audio/' + df_20.primary_label + '/' + df_20.filename\n",
    "df_20['scientific_name'] = df_20['sci_name']\n",
    "df_20['common_name'] = df_20['species']\n",
    "df_20['target'] = df_20.primary_label.map(CFG.name2label2)\n",
    "df_20['birdclef'] = '20'\n",
    "#assert tf.io.gfile.exists(df_20.filepath.iloc[0])\n",
    "\n",
    "# Xeno-Canto Extend by @vopani\n",
    "df_xam = pd.read_csv(f'{CFG.BASE_PATH4}/train_extended.csv')\n",
    "df_xam['filepath'] = CFG.BASE_PATH4 + '/A-M/' + df_xam.ebird_code + '/' + df_xam.filename\n",
    "df_xnz = pd.read_csv(f'{CFG.BASE_PATH5}/train_extended.csv')\n",
    "df_xnz['filepath'] = CFG.BASE_PATH5 + '/N-Z/' + df_xnz.ebird_code + '/' + df_xnz.filename\n",
    "df_xc = pd.concat([df_xam, df_xnz], axis=0, ignore_index=True)\n",
    "df_xc['primary_label'] = df_xc['ebird_code']\n",
    "df_xc['scientific_name'] = df_xc['sci_name']\n",
    "df_xc['common_name'] = df_xc['species']\n",
    "df_xc['target'] = df_xc.primary_label.map(CFG.name2label2)\n",
    "df_xc['birdclef'] = 'xc'\n",
    "#assert tf.io.gfile.exists(df_xc.filepath.iloc[0])\n",
    "\n",
    "# BirdCLEF-2021\n",
    "df_21 = pd.read_csv(f'{CFG.BASE_PATH1}/train_metadata.csv')\n",
    "df_21['filepath'] = CFG.BASE_PATH1 + '/train_short_audio/' + df_21.primary_label + '/' + df_21.filename\n",
    "df_21['target'] = df_21.primary_label.map(CFG.name2label2)\n",
    "df_21['birdclef'] = '21'\n",
    "corrupt_paths = [f'{CFG.BASE_PATH1}/train_short_audio/houwre/XC590621.ogg',\n",
    "                 f'{CFG.BASE_PATH1}/train_short_audio/cogdov/XC579430.ogg']\n",
    "df_21 = df_21[~df_21.filepath.isin(corrupt_paths)] # remove all zero audios\n",
    "#assert tf.io.gfile.exists(df_21.filepath.iloc[0])\n",
    "\n",
    "# BirdCLEF-2022\n",
    "df_22 = pd.read_csv(f'{CFG.BASE_PATH2}/train_metadata.csv')\n",
    "df_22['filepath'] = CFG.BASE_PATH2 + '/train_audio/' + df_22.filename\n",
    "df_22['target'] = df_22.primary_label.map(CFG.name2label2)\n",
    "df_22['birdclef'] = '22'\n",
    "#assert tf.io.gfile.exists(df_22.filepath.iloc[0])\n",
    "\n",
    "# Merge 2021 and 2022 for pretraining\n",
    "df_pre = pd.concat([df_20, df_21, df_22, df_xc], axis=0, ignore_index=True)\n",
    "df_pre['filename'] = df_pre.filepath.map(lambda x: x.split('/')[-1])\n",
    "df_pre['xc_id'] = df_pre.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\n",
    "nodup_idx = df_pre[['xc_id','primary_label','author']].drop_duplicates().index\n",
    "df_pre = df_pre.loc[nodup_idx].reset_index(drop=True)\n",
    "\n",
    "# # Remove duplicates\n",
    "df_pre = df_pre[~df_pre.xc_id.isin(df_23.xc_id)].reset_index(drop=True)\n",
    "corrupt_mp3s = json.load(open('/kaggle/input/birdclef-2023-dataset/corrupt_mp3_files.json','r'))\n",
    "corrupt_mp3s = [path.replace('/kaggle/input','/kaggle/input/birdclef-2023-dataset') for path in corrupt_mp3s]\n",
    "df_pre = df_pre[~df_pre.filepath.isin(corrupt_mp3s)]\n",
    "df_pre = df_pre[['filename','filepath','primary_label','secondary_labels',\n",
    "                 'rating','author','file_type','xc_id','scientific_name',\n",
    "                'common_name','target','birdclef','bird_seen']]\n",
    "# Display rows\n",
    "print(\"# Samples for Pre-Training: {:,}\".format(len(df_pre)))\n",
    "df_pre.head(2).style.set_caption(\"Pre-Training Data\").set_table_styles([{\n",
    "    'selector': 'caption',\n",
    "    'props': [\n",
    "        ('color', 'blue'),\n",
    "        ('font-size', '16px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "# Show distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "df_pre.birdclef.value_counts().plot.bar(color=[cmap(0.0),cmap(0.25), cmap(0.65), cmap(0.9)])\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Dataset distribution for Pre-Training\")\n",
    "plt.show()\n",
    "\n",
    "# サンプル数が合わない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre['filepath']=df_pre['filepath'].str.replace('train_audio', 'train_audio_mono_wav')\n",
    "df_pre['filepath']=df_pre['filepath'].str.replace('train_short_audio', 'train_short_audio_mono_wav')\n",
    "df_pre['filepath']=df_pre['filepath'].str.replace('A-M', 'A-M_wav')\n",
    "df_pre['filepath']=df_pre['filepath'].str.replace('mp3', 'wav')\n",
    "df_pre['filepath']=df_pre['filepath'].str.replace('ogg', 'wav')\n",
    "df_pre=df_pre.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pre.filepath.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=25.\n",
      "  UserWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "# # Import required packages\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Initialize the StratifiedKFold object with 5 splits and shuffle the data\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "# # Reset the index of the dataframe\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "# # Create a new column in the dataframe to store the fold number for each row\n",
    "# df[\"fold\"] = -1\n",
    "\n",
    "# # Iterate over the folds and assign the corresponding fold number to each row in the dataframe\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['primary_label'])):\n",
    "#     df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "# Import required packages\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize the StratifiedKFold object with 5 splits and shuffle the data\n",
    "skf1 = StratifiedKFold(n_splits=25, shuffle=True, random_state=CFG.seed)\n",
    "skf2 = StratifiedKFold(n_splits=CFG.num_fold, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "# Reset the index of the dataframe\n",
    "df_pre = df_pre.reset_index(drop=True)\n",
    "df_23 = df_23.reset_index(drop=True)\n",
    "\n",
    "# Create a new column in the dataframe to store the fold number for each row\n",
    "df_pre[\"fold\"] = -1\n",
    "df_23[\"fold\"] = -1\n",
    "\n",
    "# BirdCLEF - 21 & 22\n",
    "for fold, (train_idx, val_idx) in enumerate(skf1.split(df_pre, df_pre['primary_label'])):\n",
    "    df_pre.loc[val_idx, 'fold'] = fold\n",
    "    \n",
    "# IBirdCLEF - 23\n",
    "for fold, (train_idx, val_idx) in enumerate(skf2.split(df_23, df_23['primary_label'])):\n",
    "    df_23.loc[val_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch(batch, row=3, col=3, label2name=None,):\n",
    "    \"\"\"Plot one batch data\"\"\"\n",
    "    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "        audios, tars = batch\n",
    "    else:\n",
    "        audios = batch\n",
    "        tars = None\n",
    "    plt.figure(figsize=(col*5, row*3))\n",
    "    for idx in range(row*col):\n",
    "        ax = plt.subplot(row, col, idx+1)\n",
    "        plt.plot(audios[idx].numpy(), color=cmap(0.1))\n",
    "        if tars is not None:\n",
    "            label = tars[idx].numpy().argmax()\n",
    "            name = label2name[label]\n",
    "            plt.title(name)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_history(history):\n",
    "    \"\"\"Plot trainign history, credit: @cdeotte\"\"\"\n",
    "    epochs = len(history.history['auc'])\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(np.arange(epochs),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n",
    "    plt.plot(np.arange(epochs),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n",
    "    x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n",
    "    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n",
    "    plt.ylabel('AUC (PR)',size=14); plt.xlabel('Epoch',size=14)\n",
    "    plt.legend(loc=2)\n",
    "    plt2 = plt.gca().twinx()\n",
    "    plt2.plot(np.arange(epochs),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n",
    "    plt2.plot(np.arange(epochs),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n",
    "    x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n",
    "    ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n",
    "    plt.ylabel('Loss',size=14)\n",
    "    plt.title('Fold %i - Training Plot'%(fold+1),size=18)\n",
    "    plt.legend(loc=3)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def gc_collect():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/pre-training/exp1_pre_attblock_horizontalflip/wandb/run-20230430_122940-1ewted2z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public/runs/1ewted2z\" target=\"_blank\">fold-0|dim-313x224|model-tf_efficientnet_b1_ns|2023-04-30 21:29:36</a></strong> to <a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "#### Training\n",
      "#### Fold: 1 | Image Size: (224, 313) | Model: tf_efficientnet_b1_ns | Batch Size: 128 | Scheduler: cos\n",
      "#### Num Train: 78,407 | Num Valid: 3,216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.66s/it]\n",
      " 58%|█████▊    | 15/26 [00:44<00:32,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1586/207344335.py\", line 124, in <module>\n",
      "    for inputs, sample_info in tqdm(val_dataloader):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tqdm/std.py\", line 1195, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 681, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1359, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1325, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1163, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2098, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1586/207344335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2097\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2101\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "#%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "oof_pred = []; oof_true = []; oof_val = []; oof_ids = []; oof_folds = [] \n",
    "# Configurations\n",
    "num_classes = CFG.num_classes2\n",
    "df = df_pre.copy()\n",
    "fold = 0\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Initialize Weights and Biases\n",
    "if CFG.wandb:\n",
    "    run = wandb_init(fold)\n",
    "\n",
    "# Compute batch size and number of samples to drop\n",
    "infer_bs = CFG.valid_bs\n",
    "drop_remainder = CFG.drop_remainder\n",
    "\n",
    "# Split dataset with cv filter\n",
    "if CFG.cv_filter:\n",
    "    df = com.filter_data(df, thr=5)\n",
    "    train_df = df.query(\"fold!=@fold | ~cv\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold & cv\").reset_index(drop=True)\n",
    "else:\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "\n",
    "# Upsample train data\n",
    "train_df = com.upsample_data(train_df, thr=50)\n",
    "train_df = com.downsample_data(train_df, thr=500)\n",
    "\n",
    "# Get file paths and labels\n",
    "train_paths = train_df.filepath.values; train_labels = train_df.target.values\n",
    "valid_paths = valid_df.filepath.values; valid_labels = valid_df.target.values\n",
    "\n",
    "# Shuffle the file paths and labels\n",
    "index = np.arange(len(train_paths))\n",
    "np.random.shuffle(index)\n",
    "train_paths  = train_paths[index]\n",
    "train_labels = train_labels[index]\n",
    "\n",
    "# wav\n",
    "train_ftype = list(map(lambda x: '.wav' in x, train_paths))\n",
    "valid_ftype = list(map(lambda x: '.wav' in x, valid_paths))\n",
    "\n",
    "# Compute the number of training and validation samples\n",
    "num_train = len(train_paths); num_valid = len(valid_paths)\n",
    "    \n",
    "# Log the number of training and validation samples if Weights and Biases is being used\n",
    "if CFG.wandb:\n",
    "    wandb.log({'num_train':num_train,\n",
    "                'num_valid':num_valid})\n",
    "    \n",
    "# Build the training and validation datasets\n",
    "# For debugging\n",
    "if CFG.debug:\n",
    "    min_samples = CFG.batch_size\n",
    "    train_ds = prep.BirdDataset(train_df.iloc[:min_samples], is_train=True)\n",
    "    valid_ds = prep.BirdDataset(valid_df, is_train=False)\n",
    "else:\n",
    "    train_ds = prep.BirdDataset(train_df, is_train=True)\n",
    "    valid_ds = prep.BirdDataset(valid_df, is_train=False)\n",
    "# dataloader\n",
    "train_dataloader, val_dataloader = modeler.make_dataloder(train_ds, valid_ds)\n",
    "\n",
    "wav_to_logmel = Wav2Logmel()\n",
    "# Clear the session and build the model\n",
    "model = BirdCLEF23Net(num_classes=num_classes)\n",
    "# Load birdclef pretrained weights\n",
    "if CFG.pretrain == True:\n",
    "    model.load_state_dict(torch.load(CFG.pretrained_model_path), strict=False)\n",
    "model.to(device)\n",
    "wav_to_logmel.to(device)\n",
    "\n",
    "print('#' * 25)\n",
    "print('#### Training')\n",
    "print('#### Fold: %i | Image Size: (%i, %i) | Model: %s | Batch Size: %i | Scheduler: %s' %\n",
    "    (fold + 1, *CFG.img_size, CFG.model_name, CFG.batch_size, CFG.scheduler))\n",
    "print('#### Num Train: {:,} | Num Valid: {:,}'.format(len(train_paths), len(valid_paths)))\n",
    "\n",
    "optimizer = com.get_optimizer(model)\n",
    "# TODO com.get_scheduler\n",
    "scheduler = CosineLRScheduler(optimizer, t_initial=CFG.epochs, lr_min=CFG.lr_min, \n",
    "                                warmup_t=CFG.warmup_t, warmup_lr_init=CFG.warmup_lr_init, warmup_prefix=True)\n",
    "criterion = com.get_criterion()\n",
    "\n",
    "best_score = -1\n",
    "best_epoch = -1\n",
    "\n",
    "for epoch in range(2 if CFG.debug else CFG.epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (inputs, sample_info) in enumerate(tqdm(train_dataloader)):\n",
    "        inputs, targets = inputs.to(device), sample_info['target'].to(device)\n",
    "        targets = F.one_hot(targets, num_classes=num_classes).float()\n",
    "        optimizer.zero_grad()\n",
    "        logmel = wav_to_logmel(inputs)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs, mix_targets = model(logmel, targets)\n",
    "            loss = modeler.loss_fn(outputs, mix_targets)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if np.isinf(loss.item()) or np.isnan(loss.item()):\n",
    "            print(f'Bad loss, skipping the batch {batch_idx}')\n",
    "            del loss, outputs, mix_targets\n",
    "            gc_collect()\n",
    "            continue\n",
    "        epoch_loss += loss.item()\n",
    "        # wandb logger (Train loss)\n",
    "        run.log({'loss': loss.item()})\n",
    "    scheduler.step(epoch+1)\n",
    "    \n",
    "    # gc\n",
    "    # del logmel\n",
    "    # torch.cuda.empty_cache()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, sample_info in tqdm(val_dataloader):\n",
    "            inputs, targets = inputs.to(device), sample_info['target'].to(device)\n",
    "            targets = F.one_hot(targets, num_classes=num_classes).float()\n",
    "            logmel = wav_to_logmel(inputs)\n",
    "            outputs = model(logmel)\n",
    "            loss = modeler.loss_fn(outputs, targets)\n",
    "            outputs = outputs[\"clipwise_output\"]#torch.softmax(outputs, dim=1)\n",
    "            #outputs = torch.softmax(outputs, dim=1)\n",
    "            val_loss += loss.item()\n",
    "            val_preds.append(outputs.detach().cpu().numpy())\n",
    "            val_true.append(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_preds = np.vstack(val_preds)\n",
    "    val_true = np.vstack(val_true)\n",
    "    # Metrics\n",
    "    val_score = com.padded_cmap(val_true, val_preds)\n",
    "    # Checkpoint\n",
    "    if val_score > best_score:\n",
    "        best_score = val_score\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), f'fold-{fold}.pth')\n",
    "        art = wandb.Artifact(\"birdclef-2023\", type=\"model\")\n",
    "        art.add_file(f'fold-{fold}.pth')\n",
    "        run.log_artifact(art)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1} | Train Loss: {epoch_loss / len(train_dataloader)} | '\n",
    "        f'Val Loss: {val_loss / len(val_dataloader)} | Val Padded_cmAP : {val_score}')\n",
    "    \n",
    "    # wandb logger\n",
    "    lr = scheduler.get_epoch_values(epoch)[0]\n",
    "    run.log({'train_loss': epoch_loss / len(train_dataloader),\n",
    "             'lr': lr,\n",
    "             'epoch': epoch+1,\n",
    "             'valid_loss': val_loss / len(val_dataloader),\n",
    "             'valid_padded_cmAP': val_score,})\n",
    "    \n",
    "    \n",
    "# Load best checkpoint\n",
    "print('# Loading best model')\n",
    "model.load_state_dict(torch.load(f'fold-{fold}.pth'))\n",
    "\n",
    "# Predict on the validation data for oof result\n",
    "print('# Infering OOF')\n",
    "model.eval()\n",
    "oof_pred_ = []\n",
    "with torch.no_grad():\n",
    "    for inputs, sample_info in tqdm(val_dataloader):\n",
    "        inputs, targets = inputs.to(device), sample_info['target'].to(device)\n",
    "        logmel = wav_to_logmel(inputs)\n",
    "        outputs = model(logmel)\n",
    "        outputs = outputs[\"clipwise_output\"]#torch.softmax(outputs, dim=1)\n",
    "        oof_pred_.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "oof_pred_ = np.concatenate(oof_pred_, axis=0)\n",
    "# oof_pred : 5\n",
    "oof_pred.append(oof_pred_)\n",
    "\n",
    "# Get ids and targets\n",
    "oof_true.append(valid_labels)\n",
    "oof_folds.append(np.ones_like(oof_true[-1], dtype='int8') * fold)\n",
    "oof_ids.append(valid_paths)\n",
    "\n",
    "# Save valid data prediction\n",
    "y_true = np.array(oof_true[-1])\n",
    "y_pred = np.argmax(oof_pred[-1], axis=-1)\n",
    "\n",
    "valid_df['pred'] = y_pred\n",
    "valid_df['miss'] = y_true != y_pred\n",
    "valid_df[CFG.class_names] = oof_pred[-1].tolist()\n",
    "# Log the metrics\n",
    "scores = {}\n",
    "cmAP = com.padded_cmap(com.one_hot_encode(y_true), oof_pred[-1])\n",
    "oof_val.append(best_score)\n",
    "print('\\n>>> FOLD %i Padded_cmAP = %.3f' % (fold+1, cmAP))\n",
    "scores.update({'epoch': best_epoch,\n",
    "                'cmAP': cmAP,})\n",
    "# wandb logger \n",
    "run.log(scores)\n",
    "# Show training plot\n",
    "# if CFG.training_plot:\n",
    "#     plot_history(history)\n",
    "# Log metrics, media to wandb\n",
    "if CFG.wandb:\n",
    "    print('# WandB')\n",
    "    log_wandb(valid_df)\n",
    "    wandb.run.finish()\n",
    "    #display(ipd.IFrame(run.url, width=1080, height=720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(row):\n",
    "    row['filename'] = row['filepath'].split('/',5)[-1]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# OOF Data\n",
    "y_pred = np.concatenate(oof_pred)\n",
    "y_true = np.concatenate(oof_true)\n",
    "ids = np.concatenate(oof_ids)\n",
    "folds = np.concatenate(oof_folds)\n",
    "\n",
    "# Overall cmAP\n",
    "cmAP = com.padded_cmap(com.one_hot_encode(y_true), y_pred)\n",
    "\n",
    "# Overall AUC in PR curve\n",
    "# y_true_one_hot = torch.nn.functional.one_hot(torch.tensor(y_true))\n",
    "# y_pred_tensor = torch.tensor(y_pred)\n",
    "#auc = average_precision_score(y_true_one_hot.numpy(), y_pred_tensor.numpy(), average='macro')\n",
    "\n",
    "print('>>> Overall cmAP: ', cmAP)\n",
    "#print('>>> Overall AUC(PR): ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save OOF data to disk\n",
    "# columns = ['filepath', 'fold', 'true', 'pred', *CFG.class_names]\n",
    "# df_oof = pd.DataFrame(np.concatenate([ids[:,None], folds, y_true,\n",
    "#                                       np.argmax(y_pred,axis=1)[:,None], y_pred], axis=1), columns=columns)\n",
    "# df_oof['class_name'] = df_oof.true.map(CFG.label2name)\n",
    "# df_oof['miss'] = df_oof.true!=df_oof.pred\n",
    "# tqdm.pandas(desc='id ')\n",
    "# df_oof = df_oof.progress_apply(get_id,axis=1)\n",
    "# df_oof.to_csv('oof.csv',index=False)\n",
    "# display(df_oof.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Miss Total:')\n",
    "# display(df_oof.query(\"miss==True\").shape[0])\n",
    "\n",
    "# print()\n",
    "# print('Miss Distribution Top10:')\n",
    "# display(df_oof.query(\"miss==True\").class_name.value_counts()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
