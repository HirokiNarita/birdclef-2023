{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imprements by https://www.kaggle.com/code/awsaf49/birdclef23-effnet-fsr-cutmixup-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impoert library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "cmap = mpl.cm.get_cmap('coolwarm')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import wandb\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from timm.scheduler import CosineLRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import CFG\n",
    "from pytorch_model import BirdCLEF23Net\n",
    "import pytorch_modeler as modeler\n",
    "import pytorch_preprocessing as prep\n",
    "import common as com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Debug : False\n"
     ]
    }
   ],
   "source": [
    "modeler.set_seed(CFG.seed)\n",
    "# setting\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print('Debug :', CFG.debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhirokin1999\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local mode\n"
     ]
    }
   ],
   "source": [
    "# Try to get the API key from Kaggle secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"WANDB\")\n",
    "    # Login to wandb with the API key\n",
    "    wandb.login(key=api_key)\n",
    "    print('kaggle notebook mode')\n",
    "except:\n",
    "    key_path = '../../input/wandb_key.txt'\n",
    "    p = Path(key_path)\n",
    "    api_key = p.read_text()\n",
    "    wandb.login(key=api_key)\n",
    "    print('local mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-16 02:29:10\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを設定\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在時刻を取得し、日本時間に変換\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 現在時刻を文字列に変換\n",
    "now_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(now_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "def wandb_init(fold):\n",
    "    config = {k: v for k, v in dict(vars(CFG)).items() if '__' not in k}\n",
    "    config.update({\"fold\": int(fold)})\n",
    "    yaml.dump(config, open(f'./config fold-{fold}.yaml', 'w'), )\n",
    "    config = yaml.load(open(f'./config fold-{fold}.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "    run = wandb.init(project=\"birdclef-2023-public\",\n",
    "                     name=f\"fold-{fold}|dim-{CFG.img_size[1]}x{CFG.img_size[0]}|model-{CFG.model_name}|{now_str}\",\n",
    "                     config=config,\n",
    "                     group=CFG.comment,\n",
    "                     save_code=True, )\n",
    "    return run\n",
    "\n",
    "\n",
    "def log_wandb(valid_df):\n",
    "    save_df = valid_df.query(\"miss==True\")\n",
    "    save_df.loc[:, 'pred_name'] = save_df.pred.map(CFG.label2name)\n",
    "    save_df.loc[:, 'target_name'] = save_df.target.map(CFG.label2name)\n",
    "    if CFG.debug:\n",
    "        save_df = save_df.iloc[:CFG.batch_size * CFG.valid_bs]\n",
    "    noimg_cols = [*CFG.tab_cols, 'target', 'pred', 'target_name', 'pred_name']\n",
    "    save_df = save_df.loc[:, noimg_cols]\n",
    "\n",
    "    data = []\n",
    "    for idx, row in tqdm(save_df.iterrows(), total=len(save_df), desc='wandb ', position=0, leave=True):\n",
    "        filepath = '/kaggle/input/birdclef-2023/train_audio/' + row.filename\n",
    "        audio, sr = librosa.load(filepath, sr=None)\n",
    "        data += [[*row.tolist(), wandb.Audio(audio, caption=row.filename, sample_rate=sr)]]\n",
    "    wandb_table = wandb.Table(data=data, columns=[*noimg_cols, 'audio'])\n",
    "    wandb.log({'best': scores,\n",
    "               'table': wandb_table,\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abethr1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song']</td>\n",
       "      <td>4.3906</td>\n",
       "      <td>38.2788</td>\n",
       "      <td>Turdus tephronotus</td>\n",
       "      <td>African Bare-eyed Thrush</td>\n",
       "      <td>Rolf A. de By</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.xeno-canto.org/128013</td>\n",
       "      <td>abethr1/XC128013.ogg</td>\n",
       "      <td>/kaggle/input/birdclef-2023/train_audio_wav/ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abethr1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>-2.9524</td>\n",
       "      <td>38.2921</td>\n",
       "      <td>Turdus tephronotus</td>\n",
       "      <td>African Bare-eyed Thrush</td>\n",
       "      <td>James Bradley</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://www.xeno-canto.org/363501</td>\n",
       "      <td>abethr1/XC363501.ogg</td>\n",
       "      <td>/kaggle/input/birdclef-2023/train_audio_wav/ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  primary_label secondary_labels      type  latitude  longitude  \\\n",
       "0       abethr1               []  ['song']    4.3906    38.2788   \n",
       "1       abethr1               []  ['call']   -2.9524    38.2921   \n",
       "\n",
       "      scientific_name               common_name         author  \\\n",
       "0  Turdus tephronotus  African Bare-eyed Thrush  Rolf A. de By   \n",
       "1  Turdus tephronotus  African Bare-eyed Thrush  James Bradley   \n",
       "\n",
       "                                             license  rating  \\\n",
       "0  Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
       "1  Creative Commons Attribution-NonCommercial-Sha...     3.5   \n",
       "\n",
       "                                 url              filename  \\\n",
       "0  https://www.xeno-canto.org/128013  abethr1/XC128013.ogg   \n",
       "1  https://www.xeno-canto.org/363501  abethr1/XC363501.ogg   \n",
       "\n",
       "                                            filepath  target  \n",
       "0  /kaggle/input/birdclef-2023/train_audio_wav/ab...       0  \n",
       "1  /kaggle/input/birdclef-2023/train_audio_wav/ab...       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{CFG.BASE_PATH}/train_metadata.csv')\n",
    "filename = df.filename.str.replace('.ogg', '.wav')\n",
    "df['filepath'] = CFG.BASE_PATH + '/train_audio_wav/' + filename\n",
    "df['target'] = df.primary_label.map(CFG.name2label)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize the StratifiedKFold object with 5 splits and shuffle the data\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "# Reset the index of the dataframe\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Create a new column in the dataframe to store the fold number for each row\n",
    "df[\"fold\"] = -1\n",
    "\n",
    "# Iterate over the folds and assign the corresponding fold number to each row in the dataframe\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['primary_label'])):\n",
    "    df.loc[val_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch(batch, row=3, col=3, label2name=None,):\n",
    "    \"\"\"Plot one batch data\"\"\"\n",
    "    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "        audios, tars = batch\n",
    "    else:\n",
    "        audios = batch\n",
    "        tars = None\n",
    "    plt.figure(figsize=(col*5, row*3))\n",
    "    for idx in range(row*col):\n",
    "        ax = plt.subplot(row, col, idx+1)\n",
    "        plt.plot(audios[idx].numpy(), color=cmap(0.1))\n",
    "        if tars is not None:\n",
    "            label = tars[idx].numpy().argmax()\n",
    "            name = label2name[label]\n",
    "            plt.title(name)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_history(history):\n",
    "    \"\"\"Plot trainign history, credit: @cdeotte\"\"\"\n",
    "    epochs = len(history.history['auc'])\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(np.arange(epochs),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n",
    "    plt.plot(np.arange(epochs),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n",
    "    x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n",
    "    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n",
    "    plt.ylabel('AUC (PR)',size=14); plt.xlabel('Epoch',size=14)\n",
    "    plt.legend(loc=2)\n",
    "    plt2 = plt.gca().twinx()\n",
    "    plt2.plot(np.arange(epochs),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n",
    "    plt2.plot(np.arange(epochs),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n",
    "    x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n",
    "    ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n",
    "    plt.ylabel('Loss',size=14)\n",
    "    plt.title('Fold %i - Training Plot'%(fold+1),size=18)\n",
    "    plt.legend(loc=3)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def gc_collect():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/exp5_attblock/wandb/run-20230415_172911-2j2ri5jc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public/runs/2j2ri5jc\" target=\"_blank\">fold-0|dim-313x224|model-tf_efficientnet_b1_ns|2023-04-16 02:29:10</a></strong> to <a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "#### Training\n",
      "#### Fold: 1 | Image Size: (224, 313) | Model: tf_efficientnet_b1_ns | Batch Size: 128 | Scheduler: cos\n",
      "#### Num Train: 19,627 | Num Valid: 3,381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/154 [00:09<24:49,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/154 [00:10<11:26,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 1\n",
      "Bad loss, skipping the batch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/154 [00:11<07:07,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/154 [00:13<04:26,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 4\n",
      "Bad loss, skipping the batch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/154 [00:14<03:44,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/154 [00:17<03:18,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 7\n",
      "Bad loss, skipping the batch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/154 [00:18<03:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 10/154 [00:19<02:44,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/154 [00:19<02:32,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 13/154 [00:21<02:25,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 12\n",
      "Bad loss, skipping the batch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 14/154 [00:22<02:23,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 15/154 [00:24<02:29,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 16/154 [00:25<02:25,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 17/154 [00:25<02:17,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 19/154 [00:28<02:28,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 18\n",
      "Bad loss, skipping the batch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 20/154 [00:29<02:29,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 22/154 [00:31<02:21,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 21\n",
      "Bad loss, skipping the batch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 24/154 [00:33<02:10,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 25/154 [00:34<02:11,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 26/154 [00:35<02:14,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 25\n",
      "Bad loss, skipping the batch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 27/154 [00:36<02:17,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 28/154 [00:37<02:17,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 29/154 [00:38<02:12,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 31/154 [00:41<02:22,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 32/154 [00:42<02:11,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 33/154 [00:43<02:07,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 32\n",
      "Bad loss, skipping the batch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 34/154 [00:44<02:03,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 35/154 [00:45<02:06,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 36/154 [00:46<01:59,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 37/154 [00:47<01:54,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 39/154 [00:49<02:06,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 38\n",
      "Bad loss, skipping the batch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 40/154 [00:50<02:10,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 41/154 [00:51<02:06,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 42/154 [00:52<02:05,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 43/154 [00:53<01:57,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 44/154 [00:54<01:52,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 46/154 [00:56<01:47,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 47/154 [00:57<01:43,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 48/154 [00:58<01:37,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 49/154 [00:59<01:32,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 50/154 [01:00<01:30,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 51/154 [01:00<01:29,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 50\n",
      "Bad loss, skipping the batch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 53/154 [01:02<01:27,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 54/154 [01:03<01:26,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 55/154 [01:04<01:27,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 54\n",
      "Bad loss, skipping the batch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 56/154 [01:05<01:43,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 57/154 [01:07<01:46,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 59/154 [01:09<01:36,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 58\n",
      "Bad loss, skipping the batch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 61/154 [01:11<01:39,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 60\n",
      "Bad loss, skipping the batch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 62/154 [01:12<01:35,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 63/154 [01:13<01:38,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 64/154 [01:14<01:37,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 65/154 [01:15<01:41,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 66/154 [01:16<01:36,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 67/154 [01:17<01:36,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 68/154 [01:18<01:30,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 69/154 [01:19<01:32,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 70/154 [01:20<01:27,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 72/154 [01:23<01:26,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 71\n",
      "Bad loss, skipping the batch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 73/154 [01:23<01:20,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 75/154 [01:25<01:13,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 76/154 [01:26<01:11,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 75\n",
      "Bad loss, skipping the batch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 78/154 [01:28<01:07,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 80/154 [01:31<01:20,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 79\n",
      "Bad loss, skipping the batch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 82/154 [01:32<01:09,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 83/154 [01:33<01:04,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 82\n",
      "Bad loss, skipping the batch 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 85/154 [01:35<00:59,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 86/154 [01:36<00:58,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 87/154 [01:36<00:57,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 86\n",
      "Bad loss, skipping the batch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 89/154 [01:38<00:57,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 90/154 [01:39<00:56,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 91/154 [01:40<00:54,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 90\n",
      "Bad loss, skipping the batch 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 92/154 [01:41<00:52,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 94/154 [01:42<00:50,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 95/154 [01:43<00:49,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 96/154 [01:44<00:48,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 95\n",
      "Bad loss, skipping the batch 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 97/154 [01:45<00:50,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 98/154 [01:46<00:48,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 100/154 [01:48<00:45,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 101/154 [01:48<00:44,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 102/154 [01:49<00:43,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 103/154 [01:50<00:42,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 102\n",
      "Bad loss, skipping the batch 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 105/154 [01:52<00:41,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 106/154 [01:53<00:41,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 107/154 [01:54<00:40,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 106\n",
      "Bad loss, skipping the batch 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 108/154 [01:54<00:40,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 109/154 [01:55<00:40,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 110/154 [01:56<00:39,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 111/154 [01:57<00:39,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 112/154 [01:58<00:40,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 113/154 [01:59<00:40,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 114/154 [02:00<00:39,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 116/154 [02:02<00:36,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 117/154 [02:03<00:34,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 116\n",
      "Bad loss, skipping the batch 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 118/154 [02:04<00:33,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 119/154 [02:05<00:33,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 120/154 [02:06<00:34,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 121/154 [02:07<00:34,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 123/154 [02:09<00:30,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 122\n",
      "Bad loss, skipping the batch 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 124/154 [02:10<00:28,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 125/154 [02:11<00:28,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 126/154 [02:12<00:26,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 127/154 [02:13<00:27,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 129/154 [02:15<00:23,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 128\n",
      "Bad loss, skipping the batch 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 131/154 [02:17<00:20,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 130\n",
      "Bad loss, skipping the batch 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 133/154 [02:19<00:19,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 132\n",
      "Bad loss, skipping the batch 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 135/154 [02:20<00:17,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 136/154 [02:21<00:16,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 137/154 [02:22<00:15,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 136\n",
      "Bad loss, skipping the batch 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 139/154 [02:24<00:13,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 140/154 [02:25<00:12,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 141/154 [02:26<00:11,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 142/154 [02:27<00:10,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 143/154 [02:28<00:09,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 142\n",
      "Bad loss, skipping the batch 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 144/154 [02:28<00:08,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 146/154 [02:30<00:06,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 147/154 [02:31<00:06,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 148/154 [02:32<00:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 149/154 [02:32<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 150/154 [02:33<00:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 151/154 [02:34<00:02,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 152/154 [02:35<00:01,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 153/154 [02:35<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad loss, skipping the batch 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20432/3507577714.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mval_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# Metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mval_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/exp5_attblock/common.py\u001b[0m in \u001b[0;36mpadded_cmap\u001b[0;34m(y_true, y_pred, padding_factor)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_rows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_rows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    231\u001b[0m     )\n\u001b[1;32m    232\u001b[0m     return _average_binary_score(\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0maverage_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     )\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mnot_average_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "oof_pred = []; oof_true = []; oof_val = []; oof_ids = []; oof_folds = [] \n",
    "\n",
    "num_classes = CFG.num_classes\n",
    "df = df.copy()\n",
    "for fold in range(CFG.num_fold):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    # Check if the fold is selected\n",
    "    if fold not in CFG.selected_folds:\n",
    "        continue\n",
    "    \n",
    "    # Initialize Weights and Biases\n",
    "    if CFG.wandb:\n",
    "        run = wandb_init(fold)\n",
    "    \n",
    "    # Compute batch size and number of samples to drop\n",
    "    infer_bs = CFG.valid_bs\n",
    "    drop_remainder = CFG.drop_remainder\n",
    "    \n",
    "    # Split dataset with cv filter\n",
    "    if CFG.cv_filter:\n",
    "        df = com.filter_data(df, thr=5)\n",
    "        train_df = df.query(\"fold!=@fold | ~cv\").reset_index(drop=True)\n",
    "        valid_df = df.query(\"fold==@fold & cv\").reset_index(drop=True)\n",
    "    else:\n",
    "        train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "        valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    \n",
    "    # Upsample train data\n",
    "    train_df = com.upsample_data(train_df, thr=CFG.upsample_thr)\n",
    "#     train_df = downsample_data(train_df, thr=500)\n",
    "\n",
    "    # Get file paths and labels\n",
    "    train_paths = train_df.filepath.values; train_labels = train_df.target.values\n",
    "    valid_paths = valid_df.filepath.values; valid_labels = valid_df.target.values\n",
    "\n",
    "    # Shuffle the file paths and labels\n",
    "    index = np.arange(len(train_paths))\n",
    "    np.random.shuffle(index)\n",
    "    train_paths  = train_paths[index]\n",
    "    train_labels = train_labels[index]\n",
    "\n",
    "    # wav\n",
    "    train_ftype = list(map(lambda x: '.wav' in x, train_paths))\n",
    "    valid_ftype = list(map(lambda x: '.wav' in x, valid_paths))\n",
    "\n",
    "    # Compute the number of training and validation samples\n",
    "    num_train = len(train_paths); num_valid = len(valid_paths)\n",
    "        \n",
    "    # Log the number of training and validation samples if Weights and Biases is being used\n",
    "    if CFG.wandb:\n",
    "        wandb.log({'num_train':num_train,\n",
    "                   'num_valid':num_valid})\n",
    "        \n",
    "    # Build the training and validation datasets\n",
    "    # For debugging\n",
    "    if CFG.debug:\n",
    "        min_samples = CFG.batch_size\n",
    "        train_ds = prep.BirdDataset(train_df.iloc[:min_samples], is_train=True)\n",
    "        valid_ds = prep.BirdDataset(valid_df.iloc[:min_samples], is_train=False)\n",
    "    else:\n",
    "        train_ds = prep.BirdDataset(train_df, is_train=True)\n",
    "        valid_ds = prep.BirdDataset(valid_df, is_train=False)\n",
    "    # dataloader\n",
    "    train_dataloader, val_dataloader = modeler.make_dataloder(train_ds, valid_ds)\n",
    "    \n",
    "    # Clear the session and build the model\n",
    "    model = BirdCLEF23Net(num_classes=CFG.num_classes)\n",
    "    # Load birdclef pretrained weights\n",
    "    if CFG.pretrain == True:\n",
    "        model.load_state_dict(torch.load(CFG.pretrained_model_path), strict=False)\n",
    "    model.to(device)\n",
    "    \n",
    "    print('#' * 25)\n",
    "    print('#### Training')\n",
    "    print('#### Fold: %i | Image Size: (%i, %i) | Model: %s | Batch Size: %i | Scheduler: %s' %\n",
    "        (fold + 1, *CFG.img_size, CFG.model_name, CFG.batch_size, CFG.scheduler))\n",
    "    print('#### Num Train: {:,} | Num Valid: {:,}'.format(len(train_paths), len(valid_paths)))\n",
    "\n",
    "    optimizer = com.get_optimizer(model)\n",
    "    # TODO com.get_scheduler\n",
    "    scheduler = CosineLRScheduler(optimizer, t_initial=CFG.epochs, lr_min=CFG.lr_min, \n",
    "                                  warmup_t=CFG.warmup_t, warmup_lr_init=CFG.warmup_lr_init, warmup_prefix=True)\n",
    "    criterion = com.get_criterion()\n",
    "\n",
    "    best_score = -1\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(2 if CFG.debug else CFG.epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (inputs, sample_info) in enumerate(tqdm(train_dataloader)):\n",
    "            inputs, targets = inputs.to(device), sample_info['target'].to(device)\n",
    "            targets = F.one_hot(targets, num_classes=CFG.num_classes).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs, mix_targets = model(inputs, targets)\n",
    "            loss = modeler.loss_fn(outputs, mix_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            # wandb logger (Train loss)\n",
    "            run.log({'loss': loss.item()})\n",
    "        scheduler.step(epoch+1)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, sample_info in tqdm(val_dataloader):\n",
    "                inputs, targets = inputs.to(device), sample_info['target'].to(device)\n",
    "                targets = F.one_hot(targets, num_classes=CFG.num_classes).float()\n",
    "                outputs = model(inputs)\n",
    "                loss = modeler.loss_fn(outputs, targets)\n",
    "                outputs = outputs[\"clipwise_output\"]#torch.softmax(outputs, dim=1)\n",
    "                #outputs = torch.softmax(outputs, dim=1)\n",
    "                val_loss += loss.item()\n",
    "                val_preds.append(outputs.detach().cpu().numpy())\n",
    "                val_true.append(targets.detach().cpu().numpy())\n",
    "\n",
    "        val_preds = np.vstack(val_preds)\n",
    "        val_true = np.vstack(val_true)\n",
    "        # Metrics\n",
    "        val_score = com.padded_cmap(val_true, val_preds)\n",
    "        # Checkpoint\n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), f'fold-{fold}.pth')\n",
    "            art = wandb.Artifact(\"birdclef-2023\", type=\"model\")\n",
    "            art.add_file(f'fold-{fold}.pth')\n",
    "            run.log_artifact(art)\n",
    "\n",
    "        print(f'Epoch: {epoch + 1} | Train Loss: {epoch_loss / len(train_dataloader)} | '\n",
    "            f'Val Loss: {val_loss / len(val_dataloader)} | Val Padded_cmAP : {val_score}')\n",
    "        \n",
    "        # wandb logger\n",
    "        lr = scheduler.get_epoch_values(epoch)[0]\n",
    "        run.log({'train_loss': epoch_loss / len(train_dataloader),\n",
    "                 'lr': lr,\n",
    "                 'epoch': epoch+1,\n",
    "                 'valid_loss': val_loss / len(val_dataloader),\n",
    "                 'valid_padded_cmAP': val_score,})\n",
    "        \n",
    "        \n",
    "    # Load best checkpoint\n",
    "    print('# Loading best model')\n",
    "    model.load_state_dict(torch.load(f'fold-{fold}.pth'))\n",
    "\n",
    "    # Predict on the validation data for oof result\n",
    "    print('# Infering OOF')\n",
    "    model.eval()\n",
    "    oof_pred_ = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, sample_info in tqdm(val_dataloader):\n",
    "            inputs, targets = inputs.to(device), sample_info['target'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs[\"clipwise_output\"]#torch.softmax(outputs, dim=1)\n",
    "            oof_pred_.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "    oof_pred_ = np.concatenate(oof_pred_, axis=0)\n",
    "    # oof_pred : 5\n",
    "    oof_pred.append(oof_pred_)\n",
    "\n",
    "    # Get ids and targets\n",
    "    oof_true.append(valid_labels)\n",
    "    oof_folds.append(np.ones_like(oof_true[-1], dtype='int8') * fold)\n",
    "    oof_ids.append(valid_paths)\n",
    "\n",
    "    # Save valid data prediction\n",
    "    y_true = np.array(oof_true[-1])\n",
    "    y_pred = np.argmax(oof_pred[-1], axis=-1)\n",
    "    \n",
    "    valid_df['pred'] = y_pred\n",
    "    valid_df['miss'] = y_true != y_pred\n",
    "    valid_df[CFG.class_names] = oof_pred[-1].tolist()\n",
    "    # Log the metrics\n",
    "    scores = {}\n",
    "    cmAP = com.padded_cmap(com.one_hot_encode(y_true), oof_pred[-1])\n",
    "    oof_val.append(best_score)\n",
    "    print('\\n>>> FOLD %i Padded_cmAP = %.3f' % (fold+1, cmAP))\n",
    "    scores.update({'epoch': best_epoch,\n",
    "                   'cmAP': cmAP,})\n",
    "    # wandb logger \n",
    "    run.log(scores)\n",
    "    # Show training plot\n",
    "    # if CFG.training_plot:\n",
    "    #     plot_history(history)\n",
    "    # Log metrics, media to wandb\n",
    "    if CFG.wandb:\n",
    "        print('# WandB')\n",
    "        log_wandb(valid_df)\n",
    "        wandb.run.finish()\n",
    "        #display(ipd.IFrame(run.url, width=1080, height=720))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(row):\n",
    "    row['filename'] = row['filepath'].split('/',5)[-1]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# OOF Data\n",
    "y_pred = np.concatenate(oof_pred)\n",
    "y_true = np.concatenate(oof_true)\n",
    "ids = np.concatenate(oof_ids)\n",
    "folds = np.concatenate(oof_folds)\n",
    "\n",
    "# Overall cmAP\n",
    "cmAP = com.padded_cmap(com.one_hot_encode(y_true), y_pred)\n",
    "\n",
    "# Overall AUC in PR curve\n",
    "# y_true_one_hot = torch.nn.functional.one_hot(torch.tensor(y_true))\n",
    "# y_pred_tensor = torch.tensor(y_pred)\n",
    "#auc = average_precision_score(y_true_one_hot.numpy(), y_pred_tensor.numpy(), average='macro')\n",
    "\n",
    "print('>>> Overall cmAP: ', cmAP)\n",
    "#print('>>> Overall AUC(PR): ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save OOF data to disk\n",
    "# columns = ['filepath', 'fold', 'true', 'pred', *CFG.class_names]\n",
    "# df_oof = pd.DataFrame(np.concatenate([ids[:,None], folds, y_true,\n",
    "#                                       np.argmax(y_pred,axis=1)[:,None], y_pred], axis=1), columns=columns)\n",
    "# df_oof['class_name'] = df_oof.true.map(CFG.label2name)\n",
    "# df_oof['miss'] = df_oof.true!=df_oof.pred\n",
    "# tqdm.pandas(desc='id ')\n",
    "# df_oof = df_oof.progress_apply(get_id,axis=1)\n",
    "# df_oof.to_csv('oof.csv',index=False)\n",
    "# display(df_oof.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Miss Total:')\n",
    "# display(df_oof.query(\"miss==True\").shape[0])\n",
    "\n",
    "# print()\n",
    "# print('Miss Distribution Top10:')\n",
    "# display(df_oof.query(\"miss==True\").class_name.value_counts()[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
