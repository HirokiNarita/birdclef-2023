
  0%|          | 0/307 [00:00<?, ?it/s]
load pre-trained model :  /kaggle/working/multi_label/exp22_primary_label_2022_1st_like/fold-4.pth
<All keys matched successfully>
#########################
#### Training
#### Fold: 5 | Image Size: (128, 1001) | Model: tf_efficientnet_b1_ns | Batch Size: 64 | Scheduler: cos

















































































































































100%|██████████| 307/307 [05:07<00:00,  1.00s/it]











100%|██████████| 27/27 [00:22<00:00,  1.22it/s]
Epoch: 1 | Train Loss: 2.1724009820615042 | Val Loss: 1.377380128260012 | Val Padded_cmAP : 0.8977500484047398














































































































































100%|██████████| 307/307 [05:03<00:00,  1.01it/s]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
Epoch: 2 | Train Loss: 2.040575348204821 | Val Loss: 1.3868095322891518 | Val Padded_cmAP : 0.8983393284970348




















































































































































100%|██████████| 307/307 [05:04<00:00,  1.01it/s]










 96%|█████████▋| 26/27 [00:21<00:00,  1.39it/s]
100%|██████████| 27/27 [00:22<00:00,  1.22it/s]


















































































































































100%|██████████| 307/307 [05:16<00:00,  1.03s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/307 [00:00<?, ?it/s]





















































































































































100%|██████████| 307/307 [05:12<00:00,  1.02s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
Epoch: 5 | Train Loss: 1.934596941991427 | Val Loss: 1.3972217120506145 | Val Padded_cmAP : 0.8998366572678909




















































































































































100%|██████████| 307/307 [05:11<00:00,  1.01s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/307 [00:00<?, ?it/s]



















































































































































100%|██████████| 307/307 [05:10<00:00,  1.01s/it]









100%|██████████| 27/27 [00:22<00:00,  1.23it/s]
  0%|          | 0/307 [00:00<?, ?it/s]





















































































































































100%|██████████| 307/307 [05:07<00:00,  1.00s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/307 [00:00<?, ?it/s]





















































































































































100%|██████████| 307/307 [05:13<00:00,  1.02s/it]










100%|██████████| 27/27 [00:22<00:00,  1.23it/s]
  0%|          | 0/307 [00:00<?, ?it/s]


















































































































































100%|██████████| 307/307 [05:14<00:00,  1.02s/it]









100%|██████████| 27/27 [00:22<00:00,  1.23it/s]
  0%|          | 0/307 [00:00<?, ?it/s]
























































































































































100%|██████████| 307/307 [05:16<00:00,  1.03s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/307 [00:00<?, ?it/s]




















































































































































100%|██████████| 307/307 [05:19<00:00,  1.04s/it]










100%|██████████| 27/27 [00:22<00:00,  1.23it/s]
  0%|          | 0/307 [00:00<?, ?it/s]
























































































































































100%|██████████| 307/307 [05:21<00:00,  1.05s/it]










100%|██████████| 27/27 [00:22<00:00,  1.23it/s]
  0%|          | 0/307 [00:00<?, ?it/s]























































































































































100%|██████████| 307/307 [05:23<00:00,  1.05s/it]










100%|██████████| 27/27 [00:21<00:00,  1.66it/s]
100%|██████████| 27/27 [00:21<00:00,  1.23it/s]


























































































































































100%|██████████| 307/307 [05:19<00:00,  1.04s/it]









 89%|████████▉ | 24/27 [00:20<00:02,  1.38it/s]
100%|██████████| 27/27 [00:21<00:00,  1.23it/s]


























































































































































100%|██████████| 307/307 [05:26<00:00,  1.06s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
Epoch: 16 | Train Loss: 1.750384413846541 | Val Loss: 1.4101858525364488 | Val Padded_cmAP : 0.9021523583698481























































































































































100%|██████████| 307/307 [05:17<00:00,  1.03s/it]










100%|██████████| 27/27 [00:22<00:00,  1.22it/s]
Epoch: 17 | Train Loss: 1.7289141218514708 | Val Loss: 1.4177558510391801 | Val Padded_cmAP : 0.9031155076161921





















































































































































100%|██████████| 307/307 [05:21<00:00,  1.05s/it]









100%|██████████| 27/27 [00:22<00:00,  1.23it/s]
  0%|          | 0/307 [00:00<?, ?it/s]


























































































































































100%|██████████| 307/307 [05:17<00:00,  1.03s/it]










 96%|█████████▋| 26/27 [00:21<00:00,  1.38it/s]
100%|██████████| 27/27 [00:22<00:00,  1.23it/s]



























































































































































100%|██████████| 307/307 [05:23<00:00,  1.05s/it]










 96%|█████████▋| 26/27 [00:21<00:00,  1.38it/s]
Epoch: 20 | Train Loss: 1.7125517207558847 | Val Loss: 1.42310451136695 | Val Padded_cmAP : 0.902650382455727
100%|██████████| 27/27 [00:22<00:00,  1.23it/s]
  0%|          | 0/27 [00:00<?, ?it/s]









100%|██████████| 27/27 [00:20<00:00,  1.30it/s]
/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`
  self[col] = igetitem(value, i)
>>> FOLD 5 Primary_Padded_cmAP = 0.903
# WandB
/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.obj[key] = value

















wandb : 100%|██████████| 644/644 [00:35<00:00, 18.06it/s]