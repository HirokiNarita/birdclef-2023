load pre-trained model :  /kaggle/working/pre-training/exp1_pre_attblock_fold-0_20230501_pretrained.pth
_IncompatibleKeys(missing_keys=['model.classifier.weight', 'model.classifier.bias', 'att_block.att.weight', 'att_block.att.bias', 'att_block.cla.weight', 'att_block.cla.bias'], unexpected_keys=['to_melspec_fn.spectrogram.window', 'to_melspec_fn.mel_scale.fb'])
#########################
#### Training
#### Fold: 1 | Image Size: (224, 313) | Model: tf_efficientnet_b1_ns | Batch Size: 128 | Scheduler: cos
#### Num Train: 19,627 | Num Valid: 3,381
  0%|          | 0/1 [00:00<?, ?it/s]
100%|██████████| 1/1 [00:07<00:00,  7.44s/it]
  0%|          | 0/27 [00:00<?, ?it/s]

  4%|▎         | 1/27 [00:05<02:12,  5.10s/it]

 15%|█▍        | 4/27 [00:07<00:33,  1.45s/it]
torch.Size([128, 480000])
torch.Size([128, 480000])
torch.Size([128, 480000])

 19%|█▊        | 5/27 [00:08<00:29,  1.34s/it]
torch.Size([128, 480000])

 26%|██▌       | 7/27 [00:11<00:24,  1.25s/it]

 30%|██▉       | 8/27 [00:12<00:26,  1.39s/it]
torch.Size([128, 480000])

 41%|████      | 11/27 [00:16<00:18,  1.14s/it]
torch.Size([128, 480000])

 48%|████▊     | 13/27 [00:17<00:14,  1.03s/it]
torch.Size([128, 480000])

 56%|█████▌    | 15/27 [00:19<00:11,  1.02it/s]
torch.Size([128, 480000])

 63%|██████▎   | 17/27 [00:21<00:08,  1.12it/s]
torch.Size([128, 480000])
torch.Size([128, 480000])

 70%|███████   | 19/27 [00:23<00:07,  1.11it/s]
torch.Size([128, 480000])

 78%|███████▊  | 21/27 [00:25<00:05,  1.11it/s]
torch.Size([128, 480000])
torch.Size([128, 480000])

 89%|████████▉ | 24/27 [00:27<00:02,  1.20it/s]
torch.Size([128, 480000])

100%|██████████| 27/27 [00:29<00:00,  1.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s]

100%|██████████| 1/1 [00:06<00:00,  6.67s/it]
100%|██████████| 1/1 [00:06<00:00,  6.85s/it]
  0%|          | 0/27 [00:00<?, ?it/s]
torch.Size([128, 480000])
torch.Size([128, 480000])

  7%|▋         | 2/27 [00:07<01:21,  3.25s/it]
torch.Size([128, 480000])

 15%|█▍        | 4/27 [00:09<00:36,  1.58s/it]
torch.Size([128, 480000])

 22%|██▏       | 6/27 [00:11<00:28,  1.37s/it]
torch.Size([128, 480000])


 41%|████      | 11/27 [00:15<00:14,  1.10it/s]
torch.Size([128, 480000])

 48%|████▊     | 13/27 [00:18<00:13,  1.02it/s]
torch.Size([128, 480000])
torch.Size([128, 480000])
torch.Size([128, 480000])
torch.Size([128, 480000])

 56%|█████▌    | 15/27 [00:19<00:10,  1.09it/s]
torch.Size([128, 480000])

 63%|██████▎   | 17/27 [00:21<00:08,  1.19it/s]
torch.Size([128, 480000])
torch.Size([128, 480000])

 74%|███████▍  | 20/27 [00:23<00:05,  1.23it/s]
torch.Size([128, 480000])


 93%|█████████▎| 25/27 [00:28<00:01,  1.18it/s]
torch.Size([128, 480000])

100%|██████████| 27/27 [00:29<00:00,  1.10s/it]
torch.Size([128, 480000])
torch.Size([53, 480000])
  0%|          | 0/27 [00:00<?, ?it/s]
Epoch: 2 | Train Loss: 0.5491890907287598 | Val Loss: 0.42795089328730546 | Val Padded_cmAP : 0.45430133436658726
# Loading best model

  7%|▋         | 2/27 [00:07<01:19,  3.17s/it]
torch.Size([128, 480000])

 15%|█▍        | 4/27 [00:09<00:38,  1.68s/it]
torch.Size([128, 480000])

 22%|██▏       | 6/27 [00:11<00:27,  1.33s/it]
torch.Size([128, 480000])

 30%|██▉       | 8/27 [00:12<00:19,  1.02s/it]
torch.Size([128, 480000])
torch.Size([128, 480000])

 41%|████      | 11/27 [00:15<00:14,  1.11it/s]
torch.Size([128, 480000])

 48%|████▊     | 13/27 [00:16<00:11,  1.22it/s]
torch.Size([128, 480000])
torch.Size([128, 480000])

 56%|█████▌    | 15/27 [00:18<00:09,  1.21it/s]
torch.Size([128, 480000])

 67%|██████▋   | 18/27 [00:21<00:07,  1.16it/s]
torch.Size([128, 480000])
torch.Size([128, 480000])

 74%|███████▍  | 20/27 [00:23<00:06,  1.15it/s]
torch.Size([128, 480000])

 85%|████████▌ | 23/27 [00:25<00:03,  1.23it/s]
torch.Size([128, 480000])
torch.Size([128, 480000])

 96%|█████████▋| 26/27 [00:27<00:00,  1.33it/s]
torch.Size([128, 480000])
torch.Size([128, 480000])
100%|██████████| 27/27 [00:28<00:00,  1.05s/it]
/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`
  self[col] = igetitem(value, i)
/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.obj[key] = value
wandb :   0%|          | 0/3365 [00:00<?, ?it/s]
>>> FOLD 1 Primary_Padded_cmAP = 0.480



