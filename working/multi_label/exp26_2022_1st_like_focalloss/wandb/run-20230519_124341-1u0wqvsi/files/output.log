load pre-trained model :  /kaggle/working/WSL/exp10_softmax_model/fold-0.pth
_IncompatibleKeys(missing_keys=['bn0.weight', 'bn0.bias', 'bn0.running_mean', 'bn0.running_var', 'fc1.weight', 'fc1.bias', 'global_pool.p', 'head.weight', 'head.bias'], unexpected_keys=[])
#########################
#### Training
#### Fold: 1 | Image Size: (128, 1001) | Model: tf_efficientnet_b1_ns | Batch Size: 64 | Scheduler: cos
#### Num Train: 20,215 | Num Valid: 3,381


























































































































































100%|██████████| 316/316 [05:46<00:00,  1.10s/it]










100%|██████████| 27/27 [00:24<00:00,  1.08it/s]
Epoch: 1 | Train Loss: 3.423290764983696 | Val Loss: 0.6852653600551464 | Val Padded_cmAP : 0.4816773513412835


























































































































































100%|██████████| 316/316 [05:25<00:00,  1.03s/it]










100%|██████████| 27/27 [00:24<00:00,  1.10it/s]
Epoch: 2 | Train Loss: 0.5426482260227203 | Val Loss: 0.5518941691628209 | Val Padded_cmAP : 0.5238032919571064































































































































































100%|██████████| 316/316 [05:41<00:00,  1.08s/it]










100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
Epoch: 3 | Train Loss: 0.44831332488905024 | Val Loss: 0.3874929950193123 | Val Padded_cmAP : 0.6675854930804999





























































































































































100%|██████████| 316/316 [05:41<00:00,  1.08s/it]










 96%|█████████▋| 26/27 [00:24<00:00,  1.37it/s]
100%|██████████| 27/27 [00:24<00:00,  1.10it/s]



































































































































































100%|██████████| 316/316 [05:51<00:00,  1.11s/it]










100%|██████████| 27/27 [00:24<00:00,  1.10it/s]
  0%|          | 0/316 [00:00<?, ?it/s]
































































































































































100%|██████████| 316/316 [05:41<00:00,  1.08s/it]










100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
  0%|          | 0/316 [00:00<?, ?it/s]




































































































































































100%|██████████| 316/316 [05:52<00:00,  1.11s/it]










100%|██████████| 27/27 [00:24<00:00,  1.10it/s]
Epoch: 7 | Train Loss: 0.2583043558310859 | Val Loss: 0.28094174685301604 | Val Padded_cmAP : 0.8333466395193357



























































































































































100%|██████████| 316/316 [05:50<00:00,  1.11s/it]










100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
Epoch: 8 | Train Loss: 0.24194842091278185 | Val Loss: 0.261936720598627 | Val Padded_cmAP : 0.8409032059202161

































































































































































100%|██████████| 316/316 [05:46<00:00,  1.10s/it]










100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


































































































































































100%|██████████| 316/316 [05:44<00:00,  1.09s/it]










 96%|█████████▋| 26/27 [00:23<00:00,  1.39it/s]
100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
































































































































 79%|███████▉  | 251/316 [04:39<01:12,  1.11s/it]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py", line 3552, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "/tmp/ipykernel_26070/3007975808.py", line 108, in <module>
    for batch_idx, (inputs, sample_info) in enumerate(tqdm(train_dataloader)):
  File "/opt/conda/lib/python3.7/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1316, in _next_data
    idx, data = self._get_data()
  File "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1282, in _get_data
    success, data = self._try_get_data()
  File "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1120, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/opt/conda/lib/python3.7/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/opt/conda/lib/python3.7/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/opt/conda/lib/python3.7/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/opt/conda/lib/python3.7/multiprocessing/connection.py", line 921, in wait
    ready = selector.select(timeout)
  File "/opt/conda/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py", line 2098, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py", line 1101, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File "/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py", line 248, in wrapped
    return f(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py", line 281, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File "/opt/conda/lib/python3.7/inspect.py", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File "/opt/conda/lib/python3.7/inspect.py", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File "/opt/conda/lib/python3.7/inspect.py", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File "/opt/conda/lib/python3.7/inspect.py", line 739, in getmodule
    f = getabsfile(module)
  File "/opt/conda/lib/python3.7/inspect.py", line 708, in getabsfile
    _filename = getsourcefile(object) or getfile(object)
  File "/opt/conda/lib/python3.7/inspect.py", line 693, in getsourcefile
    if os.path.exists(filename):
  File "/opt/conda/lib/python3.7/genericpath.py", line 19, in exists
    os.stat(path)
KeyboardInterrupt
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 152, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 138, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 405, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 170, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 127, in communicate_stop_status
    resp = self._communicate_stop_status(status)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 395, in _communicate_stop_status
    resp = self._communicate(req, local=True)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
