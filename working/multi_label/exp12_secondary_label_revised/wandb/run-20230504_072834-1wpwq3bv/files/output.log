load pre-trained model :  /kaggle/working/pre-training/exp1_pre_attblock_fold-0_20230501_pretrained.pth
_IncompatibleKeys(missing_keys=['model.classifier.weight', 'model.classifier.bias', 'att_block.att.weight', 'att_block.att.bias', 'att_block.cla.weight', 'att_block.cla.bias'], unexpected_keys=['to_melspec_fn.spectrogram.window', 'to_melspec_fn.mel_scale.fb'])
#########################
#### Training
#### Fold: 1 | Image Size: (224, 313) | Model: tf_efficientnet_b1_ns | Batch Size: 128 | Scheduler: cos
#### Num Train: 19,627 | Num Valid: 3,381
100%|██████████| 1/1 [00:10<00:00, 10.70s/it]





















100%|██████████| 27/27 [00:55<00:00,  1.24s/it]
100%|██████████| 27/27 [00:55<00:00,  2.05s/it]
100%|██████████| 1/1 [00:05<00:00,  5.69s/it]


















100%|██████████| 27/27 [00:48<00:00,  1.80s/it]
Epoch: 2 | Train Loss: 0.5491890907287598 | Val Loss: 0.43375396397378707 | Val Padded_cmAP : 0.3028342585267788
# Loading best model
# Infering OOF

  7%|▋         | 2/27 [00:10<01:50,  4.43s/it]
torch.Size([320, 264])

 11%|█         | 3/27 [00:11<01:12,  3.03s/it]

 15%|█▍        | 4/27 [00:12<00:54,  2.36s/it]

 19%|█▊        | 5/27 [00:16<01:02,  2.83s/it]
torch.Size([346, 264])

 22%|██▏       | 6/27 [00:17<00:48,  2.32s/it]

 26%|██▌       | 7/27 [00:19<00:39,  1.98s/it]
torch.Size([331, 264])

 33%|███▎      | 9/27 [00:22<00:32,  1.80s/it]

 37%|███▋      | 10/27 [00:23<00:28,  1.69s/it]

 41%|████      | 11/27 [00:25<00:25,  1.61s/it]
torch.Size([336, 264])

 48%|████▊     | 13/27 [00:28<00:20,  1.49s/it]
torch.Size([322, 264])

 56%|█████▌    | 15/27 [00:32<00:20,  1.72s/it]

 59%|█████▉    | 16/27 [00:33<00:17,  1.58s/it]


 67%|██████▋   | 18/27 [00:37<00:17,  1.94s/it]

 74%|███████▍  | 20/27 [00:40<00:11,  1.69s/it]
torch.Size([305, 264])

 78%|███████▊  | 21/27 [00:42<00:09,  1.61s/it]

 81%|████████▏ | 22/27 [00:44<00:09,  1.90s/it]

 85%|████████▌ | 23/27 [00:46<00:06,  1.75s/it]
torch.Size([357, 264])
torch.Size([336, 264])

 93%|█████████▎| 25/27 [00:48<00:02,  1.50s/it]
torch.Size([308, 264])

100%|██████████| 27/27 [00:50<00:00,  1.87s/it]
Process wandb_internal:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/internal/internal.py", line 160, in wandb_internal
    thread.join()
  File "/opt/conda/lib/python3.7/threading.py", line 1044, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.7/threading.py", line 1060, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.7/multiprocessing/spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
  File "/opt/conda/lib/python3.7/multiprocessing/spawn.py", line 118, in _main
    return self._bootstrap()
  File "/opt/conda/lib/python3.7/multiprocessing/process.py", line 315, in _bootstrap
    threading._shutdown()
  File "/opt/conda/lib/python3.7/threading.py", line 1307, in _shutdown
    lock.acquire()
KeyboardInterrupt
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 152, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 138, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 405, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 170, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 127, in communicate_stop_status
    resp = self._communicate_stop_status(status)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 395, in _communicate_stop_status
    resp = self._communicate(req, local=True)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
