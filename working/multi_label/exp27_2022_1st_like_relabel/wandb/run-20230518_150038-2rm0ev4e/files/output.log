load pre-trained model :  /kaggle/working/multi_label/exp22_primary_label_2022_1st_like/fold-0.pth
<All keys matched successfully>
#########################
#### Training
#### Fold: 1 | Image Size: (128, 1001) | Model: tf_efficientnet_b1_ns | Batch Size: 64 | Scheduler: cos
#### Num Train: 20,215 | Num Valid: 3,381




















































































































































100%|██████████| 316/316 [05:29<00:00,  1.04s/it]










100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
Epoch: 1 | Train Loss: 2.1200509090212325 | Val Loss: 1.384170914137805 | Val Padded_cmAP : 0.9016837033221341






















































































































































100%|██████████| 316/316 [05:05<00:00,  1.03it/s]










100%|██████████| 27/27 [00:23<00:00,  1.64it/s]
100%|██████████| 27/27 [00:24<00:00,  1.12it/s]





























































































































































100%|██████████| 316/316 [05:29<00:00,  1.04s/it]










 96%|█████████▋| 26/27 [00:23<00:00,  1.36it/s]
100%|██████████| 27/27 [00:24<00:00,  1.11it/s]





















































































































































100%|██████████| 316/316 [05:09<00:00,  1.02it/s]










100%|██████████| 27/27 [00:23<00:00,  1.14it/s]
Epoch: 4 | Train Loss: 1.9208624992944017 | Val Loss: 1.3708003671080977 | Val Padded_cmAP : 0.9024022252628241






















































































































































100%|██████████| 316/316 [05:13<00:00,  1.01it/s]










100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/316 [00:00<?, ?it/s]






















































































































































100%|██████████| 316/316 [05:13<00:00,  1.01it/s]










 96%|█████████▋| 26/27 [00:23<00:00,  1.39it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]























































































































































100%|██████████| 316/316 [05:15<00:00,  1.00it/s]









100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/316 [00:00<?, ?it/s]





















































































































































100%|██████████| 316/316 [05:14<00:00,  1.00it/s]










100%|██████████| 27/27 [00:23<00:00,  1.66it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]

























































































































































100%|██████████| 316/316 [05:16<00:00,  1.00s/it]










100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/316 [00:00<?, ?it/s]




























































































































































100%|██████████| 316/316 [05:20<00:00,  1.01s/it]










100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/316 [00:00<?, ?it/s]























































































































































100%|██████████| 316/316 [05:23<00:00,  1.02s/it]










100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
  0%|          | 0/316 [00:00<?, ?it/s]




























































































































































100%|██████████| 316/316 [05:24<00:00,  1.03s/it]










100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
Epoch: 12 | Train Loss: 1.7742514146279684 | Val Loss: 1.405060272525858 | Val Padded_cmAP : 0.9030328479130684





























































































































































100%|██████████| 316/316 [05:30<00:00,  1.05s/it]










 93%|█████████▎| 25/27 [00:22<00:01,  1.38it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]

































































































































































100%|██████████| 316/316 [05:34<00:00,  1.06s/it]









 93%|█████████▎| 25/27 [00:22<00:01,  1.38it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]

























































































































































100%|██████████| 316/316 [05:30<00:00,  1.04s/it]









100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/316 [00:00<?, ?it/s]
































































































































































100%|██████████| 316/316 [05:42<00:00,  1.08s/it]









 93%|█████████▎| 25/27 [00:22<00:01,  1.39it/s]
100%|██████████| 27/27 [00:24<00:00,  1.12it/s]

































































































































































100%|██████████| 316/316 [05:43<00:00,  1.09s/it]










 96%|█████████▋| 26/27 [00:23<00:00,  1.39it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]


























































































































































100%|██████████| 316/316 [05:24<00:00,  1.03s/it]










 93%|█████████▎| 25/27 [00:22<00:01,  1.39it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]




























































































































































100%|██████████| 316/316 [05:28<00:00,  1.04s/it]










 96%|█████████▋| 26/27 [00:23<00:00,  1.38it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]



























































































































































100%|██████████| 316/316 [05:33<00:00,  1.05s/it]









100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/27 [00:00<?, ?it/s]
Epoch: 20 | Train Loss: 1.7041985686821273 | Val Loss: 1.4026942915386624 | Val Padded_cmAP : 0.9039868819408727
# Loading best model









100%|██████████| 27/27 [00:21<00:00,  1.25it/s]
/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`
  self[col] = igetitem(value, i)
>>> FOLD 1 Primary_Padded_cmAP = 0.905
# WandB
/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.obj[key] = value
wandb :   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.
  return f(*args, **kwargs)
