load pre-trained model :  /kaggle/working/WSL/exp10_softmax_model/fold-0.pth
_IncompatibleKeys(missing_keys=['bn0.weight', 'bn0.bias', 'bn0.running_mean', 'bn0.running_var', 'fc1.weight', 'fc1.bias', 'global_pool.p', 'head.weight', 'head.bias'], unexpected_keys=[])
#########################
#### Training
#### Fold: 1 | Image Size: (128, 1001) | Model: tf_efficientnet_b1_ns | Batch Size: 64 | Scheduler: cos
#### Num Train: 20,215 | Num Valid: 3,381




























































































































































100%|██████████| 316/316 [05:30<00:00,  1.04s/it]










100%|██████████| 27/27 [00:24<00:00,  1.10it/s]
Epoch: 1 | Train Loss: 3.446345249497438 | Val Loss: 0.6818378788453562 | Val Padded_cmAP : 0.4817395392086755




























































































































































100%|██████████| 316/316 [05:29<00:00,  1.04s/it]










100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
Epoch: 2 | Train Loss: 0.5677617646848099 | Val Loss: 0.5483391566409005 | Val Padded_cmAP : 0.5240329820438032































































































































































100%|██████████| 316/316 [05:40<00:00,  1.08s/it]










100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
  0%|          | 0/316 [00:00<?, ?it/s]





























































































































































100%|██████████| 316/316 [05:24<00:00,  1.03s/it]










100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


























































































































































100%|██████████| 316/316 [05:27<00:00,  1.04s/it]










100%|██████████| 27/27 [00:24<00:00,  1.10it/s]
Epoch: 5 | Train Loss: 0.3372573059853874 | Val Loss: 0.29249562819798786 | Val Padded_cmAP : 0.8065207496182004






























































































































































100%|██████████| 316/316 [05:28<00:00,  1.04s/it]










100%|██████████| 27/27 [00:24<00:00,  1.09it/s]
Epoch: 6 | Train Loss: 0.31151896734026413 | Val Loss: 0.26381941470834946 | Val Padded_cmAP : 0.8255205395213796


































































































































































100%|██████████| 316/316 [05:42<00:00,  1.08s/it]









100%|██████████| 27/27 [00:24<00:00,  1.10it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


































































































































































100%|██████████| 316/316 [05:33<00:00,  1.05s/it]









100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
  0%|          | 0/316 [00:00<?, ?it/s]































































































































































100%|██████████| 316/316 [05:37<00:00,  1.07s/it]










100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
Epoch: 9 | Train Loss: 0.2542924679627147 | Val Loss: 0.2295351872841517 | Val Padded_cmAP : 0.8536274968896277



































































































































































100%|██████████| 316/316 [05:50<00:00,  1.11s/it]










100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
  0%|          | 0/316 [00:00<?, ?it/s]
































































































































































100%|██████████| 316/316 [05:42<00:00,  1.08s/it]










100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
Epoch: 11 | Train Loss: 0.2406963805986356 | Val Loss: 0.23215528246429232 | Val Padded_cmAP : 0.8608153181367323
































































































































































100%|██████████| 316/316 [05:35<00:00,  1.06s/it]









100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
  0%|          | 0/316 [00:00<?, ?it/s]




























































































































































100%|██████████| 316/316 [05:40<00:00,  1.08s/it]









 89%|████████▉ | 24/27 [00:22<00:02,  1.37it/s]
100%|██████████| 27/27 [00:24<00:00,  1.12it/s]























































































































































100%|██████████| 316/316 [05:26<00:00,  1.03s/it]










100%|██████████| 27/27 [00:24<00:00,  1.10it/s]
Epoch: 14 | Train Loss: 0.2211155281696893 | Val Loss: 0.23575906676274758 | Val Padded_cmAP : 0.8666483209668884






























































































































































100%|██████████| 316/316 [05:34<00:00,  1.06s/it]









 93%|█████████▎| 25/27 [00:23<00:01,  1.38it/s]
100%|██████████| 27/27 [00:24<00:00,  1.11it/s]































































































































































100%|██████████| 316/316 [05:38<00:00,  1.07s/it]










100%|██████████| 27/27 [00:24<00:00,  1.10it/s]
Epoch: 16 | Train Loss: 0.21317167155727557 | Val Loss: 0.2409166290804192 | Val Padded_cmAP : 0.860839688676716













  8%|▊         | 25/316 [00:37<07:20,  1.51s/it]
Process wandb_internal:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/internal/internal.py", line 160, in wandb_internal
    thread.join()
  File "/opt/conda/lib/python3.7/threading.py", line 1044, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.7/threading.py", line 1060, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.7/multiprocessing/spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
  File "/opt/conda/lib/python3.7/multiprocessing/spawn.py", line 118, in _main
    return self._bootstrap()
  File "/opt/conda/lib/python3.7/multiprocessing/process.py", line 315, in _bootstrap
    threading._shutdown()
  File "/opt/conda/lib/python3.7/threading.py", line 1307, in _shutdown
    lock.acquire()
KeyboardInterrupt
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 170, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 127, in communicate_stop_status
    resp = self._communicate_stop_status(status)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 395, in _communicate_stop_status
    resp = self._communicate(req, local=True)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 152, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 138, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 405, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
