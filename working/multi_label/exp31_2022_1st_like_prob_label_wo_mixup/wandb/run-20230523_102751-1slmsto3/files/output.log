load pre-trained model :  /kaggle/working/multi_label/exp22_primary_label_2022_1st_like/fold-2.pth
<All keys matched successfully>
#########################
#### Training
#### Fold: 3 | Image Size: (128, 1001) | Model: tf_efficientnet_b1_ns | Batch Size: 64 | Scheduler: cos
#### Num Train: 20,217 | Num Valid: 3,381








































































































































































100%|██████████| 316/316 [06:16<00:00,  1.19s/it]










 96%|█████████▋| 26/27 [00:21<00:00,  1.40it/s]
100%|██████████| 27/27 [00:21<00:00,  1.24it/s]


































































































































































100%|██████████| 316/316 [06:17<00:00,  1.20s/it]










 93%|█████████▎| 25/27 [00:20<00:01,  1.38it/s]
100%|██████████| 27/27 [00:22<00:00,  1.23it/s]









































































































































































100%|██████████| 316/316 [06:21<00:00,  1.21s/it]









100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]







































































































































































100%|██████████| 316/316 [06:19<00:00,  1.20s/it]









 93%|█████████▎| 25/27 [00:20<00:01,  1.39it/s]
100%|██████████| 27/27 [00:21<00:00,  1.23it/s]










































































































































































100%|██████████| 316/316 [06:12<00:00,  1.18s/it]










 96%|█████████▋| 26/27 [00:21<00:00,  1.41it/s]
100%|██████████| 27/27 [00:21<00:00,  1.24it/s]



































































































































































100%|██████████| 316/316 [06:03<00:00,  1.15s/it]









 93%|█████████▎| 25/27 [00:20<00:01,  1.41it/s]
100%|██████████| 27/27 [00:21<00:00,  1.24it/s]



































































































































































100%|██████████| 316/316 [06:06<00:00,  1.16s/it]









100%|██████████| 27/27 [00:21<00:00,  1.25it/s]
  0%|          | 0/316 [00:00<?, ?it/s]






































































































































































100%|██████████| 316/316 [06:01<00:00,  1.14s/it]










100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
Epoch: 8 | Train Loss: 2.339994257009482 | Val Loss: 1.4823347528775532 | Val Padded_cmAP : 0.8963407111536483





































































































































































100%|██████████| 316/316 [06:11<00:00,  1.18s/it]










100%|██████████| 27/27 [00:21<00:00,  1.25it/s]
Epoch: 9 | Train Loss: 2.3528844129435624 | Val Loss: 1.4904418079941362 | Val Padded_cmAP : 0.8949827569814006




































































































































































100%|██████████| 316/316 [06:04<00:00,  1.15s/it]









100%|██████████| 27/27 [00:21<00:00,  1.25it/s]
  0%|          | 0/316 [00:00<?, ?it/s]

































































































































































100%|██████████| 316/316 [05:59<00:00,  1.14s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]






































































































































































100%|██████████| 316/316 [06:02<00:00,  1.15s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]






























































































































































100%|██████████| 316/316 [05:59<00:00,  1.14s/it]










100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]



































































































































































100%|██████████| 316/316 [05:48<00:00,  1.10s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


























































































































































100%|██████████| 316/316 [05:51<00:00,  1.11s/it]









 93%|█████████▎| 25/27 [00:20<00:01,  1.41it/s]
100%|██████████| 27/27 [00:21<00:00,  1.25it/s]































































































































































100%|██████████| 316/316 [05:39<00:00,  1.07s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
Epoch: 16 | Train Loss: 2.2085770376120943 | Val Loss: 1.4953902187170807 | Val Padded_cmAP : 0.8964011825162935



































































































































































100%|██████████| 316/316 [05:48<00:00,  1.10s/it]










 96%|█████████▋| 26/27 [00:21<00:00,  1.40it/s]
100%|██████████| 27/27 [00:21<00:00,  1.23it/s]

































































































































































100%|██████████| 316/316 [05:41<00:00,  1.08s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
Epoch: 18 | Train Loss: 2.198702780506279 | Val Loss: 1.5088238230458013 | Val Padded_cmAP : 0.8977401145107535




























































































































































100%|██████████| 316/316 [05:35<00:00,  1.06s/it]










100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
Epoch: 19 | Train Loss: 2.188123202776607 | Val Loss: 1.498952673541175 | Val Padded_cmAP : 0.8972991695245954






























































































































































100%|██████████| 316/316 [05:43<00:00,  1.09s/it]









100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/27 [00:00<?, ?it/s]
Epoch: 20 | Train Loss: 2.18522006876861 | Val Loss: 1.504661824968126 | Val Padded_cmAP : 0.8966366275708525
# Loading best model










100%|██████████| 27/27 [00:20<00:00,  1.33it/s]
/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`
  self[col] = igetitem(value, i)
/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.obj[key] = value
wandb :   3%|▎         | 19/663 [00:01<00:40, 16.01it/s]
>>> FOLD 3 Primary_Padded_cmAP = 0.898





















wandb : 100%|██████████| 663/663 [00:42<00:00, 15.45it/s]