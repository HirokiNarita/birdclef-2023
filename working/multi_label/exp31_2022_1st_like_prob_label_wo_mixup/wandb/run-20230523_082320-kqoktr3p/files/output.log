load pre-trained model :  /kaggle/working/multi_label/exp22_primary_label_2022_1st_like/fold-1.pth
<All keys matched successfully>
#########################
#### Training
#### Fold: 2 | Image Size: (128, 1001) | Model: tf_efficientnet_b1_ns | Batch Size: 64 | Scheduler: cos
#### Num Train: 20,217 | Num Valid: 3,382























































































































































100%|██████████| 316/316 [05:22<00:00,  1.02s/it]










 96%|█████████▋| 26/27 [00:21<00:00,  1.41it/s]
100%|██████████| 27/27 [00:21<00:00,  1.24it/s]


























































































































































100%|██████████| 316/316 [05:30<00:00,  1.05s/it]










100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
Epoch: 2 | Train Loss: 2.5903588465497465 | Val Loss: 1.4697337448596954 | Val Padded_cmAP : 0.9019198205265334
























































































































































100%|██████████| 316/316 [05:29<00:00,  1.04s/it]









100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]






























































































































































100%|██████████| 316/316 [05:34<00:00,  1.06s/it]










100%|██████████| 27/27 [00:21<00:00,  1.66it/s]
100%|██████████| 27/27 [00:21<00:00,  1.23it/s]























































































































































100%|██████████| 316/316 [05:25<00:00,  1.03s/it]









 93%|█████████▎| 25/27 [00:20<00:01,  1.40it/s]
100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
























































































































































100%|██████████| 316/316 [05:28<00:00,  1.04s/it]









100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]




























































































































































100%|██████████| 316/316 [05:33<00:00,  1.06s/it]









100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


























































































































































100%|██████████| 316/316 [05:27<00:00,  1.04s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]



























































































































































100%|██████████| 316/316 [05:28<00:00,  1.04s/it]










100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]




























































































































































100%|██████████| 316/316 [05:30<00:00,  1.05s/it]










100%|██████████| 27/27 [00:22<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]
























































































































































100%|██████████| 316/316 [05:29<00:00,  1.04s/it]










 96%|█████████▋| 26/27 [00:21<00:00,  1.41it/s]
100%|██████████| 27/27 [00:21<00:00,  1.24it/s]





























































































































































100%|██████████| 316/316 [05:31<00:00,  1.05s/it]









100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]





























































































































































100%|██████████| 316/316 [05:31<00:00,  1.05s/it]









100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]
























































































































































100%|██████████| 316/316 [05:26<00:00,  1.03s/it]










100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
Epoch: 14 | Train Loss: 2.207634936027889 | Val Loss: 1.500527348783281 | Val Padded_cmAP : 0.9024417997978915



























































































































































100%|██████████| 316/316 [05:29<00:00,  1.04s/it]









 93%|█████████▎| 25/27 [00:20<00:01,  1.40it/s]
100%|██████████| 27/27 [00:21<00:00,  1.24it/s]





































































































































































100%|██████████| 316/316 [06:27<00:00,  1.23s/it]










 96%|█████████▋| 26/27 [00:21<00:00,  1.40it/s]
100%|██████████| 27/27 [00:22<00:00,  1.21it/s]












































































































































































100%|██████████| 316/316 [06:36<00:00,  1.26s/it]










100%|██████████| 27/27 [00:22<00:00,  1.22it/s]
  0%|          | 0/316 [00:00<?, ?it/s]










































































































































































100%|██████████| 316/316 [06:35<00:00,  1.25s/it]










 96%|█████████▋| 26/27 [00:22<00:00,  1.40it/s]
100%|██████████| 27/27 [00:22<00:00,  1.18it/s]








































































































































































100%|██████████| 316/316 [06:41<00:00,  1.27s/it]









100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]






































































































































































100%|██████████| 316/316 [06:18<00:00,  1.20s/it]










 96%|█████████▋| 26/27 [00:21<00:00,  1.41it/s]
Epoch: 20 | Train Loss: 2.139431663329088 | Val Loss: 1.5172547653869346 | Val Padded_cmAP : 0.9021622493218645
100%|██████████| 27/27 [00:21<00:00,  1.25it/s]
  0%|          | 0/27 [00:00<?, ?it/s]










100%|██████████| 27/27 [00:20<00:00,  1.33it/s]
>>> FOLD 2 Primary_Padded_cmAP = 0.904
# WandB
/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`
  self[col] = igetitem(value, i)
/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.obj[key] = value























wandb : 100%|██████████| 669/669 [00:49<00:00, 13.48it/s]