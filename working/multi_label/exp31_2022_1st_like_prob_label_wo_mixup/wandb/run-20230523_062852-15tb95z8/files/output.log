
  0%|          | 0/316 [00:00<?, ?it/s]
load pre-trained model :  /kaggle/working/multi_label/exp22_primary_label_2022_1st_like/fold-0.pth
<All keys matched successfully>
#########################
#### Training
#### Fold: 1 | Image Size: (128, 1001) | Model: tf_efficientnet_b1_ns | Batch Size: 64 | Scheduler: cos
















































































































































100%|██████████| 316/316 [05:03<00:00,  1.04it/s]










100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
Epoch: 1 | Train Loss: 2.7730002339127697 | Val Loss: 1.4253970517052545 | Val Padded_cmAP : 0.8991035816107337


















































































































































100%|██████████| 316/316 [05:11<00:00,  1.01it/s]











100%|██████████| 27/27 [00:28<00:00,  1.04s/it]
Epoch: 2 | Train Loss: 2.5734129631066622 | Val Loss: 1.4120124225263242 | Val Padded_cmAP : 0.9007272930216205




























































































































































100%|██████████| 316/316 [05:33<00:00,  1.06s/it]









 93%|█████████▎| 25/27 [00:22<00:01,  1.40it/s]
100%|██████████| 27/27 [00:24<00:00,  1.12it/s]















































































































































100%|██████████| 316/316 [04:57<00:00,  1.06it/s]









100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
  0%|          | 0/316 [00:00<?, ?it/s]
















































































































































100%|██████████| 316/316 [04:59<00:00,  1.06it/s]









100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
  0%|          | 0/316 [00:00<?, ?it/s]















































































































































100%|██████████| 316/316 [04:56<00:00,  1.06it/s]










100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
  0%|          | 0/316 [00:00<?, ?it/s]
















































































































































100%|██████████| 316/316 [05:00<00:00,  1.05it/s]









100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/316 [00:00<?, ?it/s]



















































































































































100%|██████████| 316/316 [05:07<00:00,  1.03it/s]










 96%|█████████▋| 26/27 [00:23<00:00,  1.39it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]





















































































































































100%|██████████| 316/316 [05:10<00:00,  1.02it/s]









100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/316 [00:00<?, ?it/s]

















































































































































100%|██████████| 316/316 [05:09<00:00,  1.02it/s]










100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


















































































































































100%|██████████| 316/316 [05:06<00:00,  1.03it/s]









100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


























































































































































100%|██████████| 316/316 [05:18<00:00,  1.01s/it]









100%|██████████| 27/27 [00:24<00:00,  1.11it/s]
  0%|          | 0/316 [00:00<?, ?it/s]

























































































































































100%|██████████| 316/316 [05:23<00:00,  1.02s/it]









 93%|█████████▎| 25/27 [00:22<00:01,  1.39it/s]
100%|██████████| 27/27 [00:24<00:00,  1.12it/s]



















































































































































100%|██████████| 316/316 [05:16<00:00,  1.00s/it]









100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/316 [00:00<?, ?it/s]























































































































































100%|██████████| 316/316 [05:21<00:00,  1.02s/it]









 93%|█████████▎| 25/27 [00:22<00:01,  1.40it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]

























































































































































100%|██████████| 316/316 [05:29<00:00,  1.04s/it]










100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
Epoch: 16 | Train Loss: 2.1837707878668096 | Val Loss: 1.4650189170130976 | Val Padded_cmAP : 0.901491137029212


























































































































































100%|██████████| 316/316 [05:20<00:00,  1.02s/it]










 93%|█████████▎| 25/27 [00:22<00:01,  1.40it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]






















































































































































100%|██████████| 316/316 [05:14<00:00,  1.01it/s]









100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


























































































































































100%|██████████| 316/316 [05:16<00:00,  1.00s/it]









100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
  0%|          | 0/316 [00:00<?, ?it/s]



















































































































































100%|██████████| 316/316 [05:20<00:00,  1.01s/it]










100%|██████████| 27/27 [00:24<00:00,  1.12it/s]
Epoch: 20 | Train Loss: 2.142902553458757 | Val Loss: 1.4325656294822693 | Val Padded_cmAP : 0.9025866695364576
# Loading best model
# Infering OOF










 96%|█████████▋| 26/27 [00:21<00:00,  1.39it/s]
>>> FOLD 1 Primary_Padded_cmAP = 0.903
100%|██████████| 27/27 [00:21<00:00,  1.26it/s]
/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`
  self[col] = igetitem(value, i)
/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.obj[key] = value





















wandb : 100%|██████████| 656/656 [00:44<00:00, 14.88it/s]