load pre-trained model :  /kaggle/working/multi_label/exp22_primary_label_2022_1st_like/fold-3.pth
<All keys matched successfully>
#########################
#### Training
#### Fold: 4 | Image Size: (128, 1001) | Model: tf_efficientnet_b1_ns | Batch Size: 64 | Scheduler: cos
#### Num Train: 20,211 | Num Valid: 3,381


































































































































































100%|██████████| 316/316 [05:46<00:00,  1.10s/it]










100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
Epoch: 1 | Train Loss: 2.7776642468156694 | Val Loss: 1.540779091693737 | Val Padded_cmAP : 0.8874735572444151





























































































































































100%|██████████| 316/316 [05:38<00:00,  1.07s/it]










100%|██████████| 27/27 [00:22<00:00,  1.21it/s]
Epoch: 2 | Train Loss: 2.6107027311868305 | Val Loss: 1.5175163679652743 | Val Padded_cmAP : 0.8899884338733186



























































































































































100%|██████████| 316/316 [05:34<00:00,  1.06s/it]









 93%|█████████▎| 25/27 [00:20<00:01,  1.40it/s]
100%|██████████| 27/27 [00:21<00:00,  1.24it/s]































































































































































100%|██████████| 316/316 [05:32<00:00,  1.05s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]




























































































































































100%|██████████| 316/316 [05:33<00:00,  1.06s/it]









100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


























































































































































100%|██████████| 316/316 [05:33<00:00,  1.06s/it]









100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]




























































































































































100%|██████████| 316/316 [05:32<00:00,  1.05s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]



























































































































































100%|██████████| 316/316 [05:23<00:00,  1.02s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


























































































































































100%|██████████| 316/316 [05:20<00:00,  1.01s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]
































































































































































100%|██████████| 316/316 [05:34<00:00,  1.06s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


























































































































































100%|██████████| 316/316 [05:28<00:00,  1.04s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]



























































































































































100%|██████████| 316/316 [05:31<00:00,  1.05s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]































































































































































100%|██████████| 316/316 [05:39<00:00,  1.07s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]




























































































































































100%|██████████| 316/316 [05:32<00:00,  1.05s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
Epoch: 14 | Train Loss: 2.2043377319468727 | Val Loss: 1.5431179095197607 | Val Padded_cmAP : 0.8917731960085544































































































































































100%|██████████| 316/316 [05:42<00:00,  1.08s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]




























































































































































100%|██████████| 316/316 [05:30<00:00,  1.04s/it]










100%|██████████| 27/27 [00:21<00:00,  1.24it/s]
  0%|          | 0/316 [00:00<?, ?it/s]































































































































































100%|██████████| 316/316 [05:32<00:00,  1.05s/it]










 96%|█████████▋| 26/27 [00:21<00:00,  1.39it/s]
100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
































































































































































100%|██████████| 316/316 [05:43<00:00,  1.09s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]





























































































































































100%|██████████| 316/316 [05:38<00:00,  1.07s/it]









100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
  0%|          | 0/316 [00:00<?, ?it/s]

































































































































































100%|██████████| 316/316 [05:36<00:00,  1.06s/it]










100%|██████████| 27/27 [00:21<00:00,  1.23it/s]
Epoch: 20 | Train Loss: 2.162762970109529 | Val Loss: 1.5361773195090118 | Val Padded_cmAP : 0.8924282230058983
# Loading best model
# Infering OOF









100%|██████████| 27/27 [00:20<00:00,  1.31it/s]
/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`
  self[col] = igetitem(value, i)
/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.obj[key] = value
wandb :   0%|          | 0/676 [00:00<?, ?it/s]
>>> FOLD 4 Primary_Padded_cmAP = 0.893






















wandb : 100%|██████████| 676/676 [00:43<00:00, 15.72it/s]