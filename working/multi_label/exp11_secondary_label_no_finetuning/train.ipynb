{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imprements by https://www.kaggle.com/code/awsaf49/birdclef23-effnet-fsr-cutmixup-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impoert library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "cmap = mpl.cm.get_cmap('coolwarm')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import wandb\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from timm.scheduler import CosineLRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import CFG\n",
    "from pytorch_model import BirdCLEF23Net\n",
    "from pytorch_wav2logmel import Wav2Logmel\n",
    "import pytorch_modeler as modeler\n",
    "import pytorch_preprocessing as prep\n",
    "import common as com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Debug : False\n"
     ]
    }
   ],
   "source": [
    "modeler.set_seed(CFG.seed)\n",
    "# setting\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print('Debug :', CFG.debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhirokin1999\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local mode\n"
     ]
    }
   ],
   "source": [
    "# Try to get the API key from Kaggle secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"WANDB\")\n",
    "    # Login to wandb with the API key\n",
    "    wandb.login(key=api_key)\n",
    "    print('kaggle notebook mode')\n",
    "except:\n",
    "    key_path = '/kaggle/input/wandb_key.txt'\n",
    "    p = Path(key_path)\n",
    "    api_key = p.read_text()\n",
    "    wandb.login(key=api_key)\n",
    "    print('local mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-04 19:58:58\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを設定\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在時刻を取得し、日本時間に変換\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 現在時刻を文字列に変換\n",
    "now_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(now_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "def wandb_init(fold):\n",
    "    config = {k: v for k, v in dict(vars(CFG)).items() if '__' not in k}\n",
    "    config.update({\"fold\": int(fold)})\n",
    "    yaml.dump(config, open(f'./config fold-{fold}.yaml', 'w'), )\n",
    "    config = yaml.load(open(f'./config fold-{fold}.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "    run = wandb.init(project=\"birdclef-2023-public\",\n",
    "                     name=f\"fold-{fold}|dim-{CFG.img_size[1]}x{CFG.img_size[0]}|model-{CFG.model_name}|{now_str}\",\n",
    "                     config=config,\n",
    "                     group=CFG.comment,\n",
    "                     save_code=True, )\n",
    "    return run\n",
    "\n",
    "\n",
    "def log_wandb(valid_df):\n",
    "    save_df = valid_df.query(\"miss==True\")\n",
    "    save_df.loc[:, 'pred_name'] = save_df.pred.map(CFG.label2name)\n",
    "    save_df.loc[:, 'target_name'] = save_df.target.map(CFG.label2name)\n",
    "    if CFG.debug:\n",
    "        save_df = save_df.iloc[:CFG.batch_size * CFG.valid_bs]\n",
    "    noimg_cols = [*CFG.tab_cols, 'target', 'pred', 'target_name', 'pred_name']\n",
    "    save_df = save_df.loc[:, noimg_cols]\n",
    "\n",
    "    data = []\n",
    "    for idx, row in tqdm(save_df.iterrows(), total=len(save_df), desc='wandb ', position=0, leave=True):\n",
    "        filepath = '/kaggle/input/birdclef-2023/train_audio/' + row.filename\n",
    "        audio, sr = librosa.load(filepath, sr=None)\n",
    "        data += [[*row.tolist(), wandb.Audio(audio, caption=row.filename, sample_rate=sr)]]\n",
    "    wandb_table = wandb.Table(data=data, columns=[*noimg_cols, 'audio'])\n",
    "    wandb.log({'best': scores,\n",
    "               'table': wandb_table,\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abethr1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song']</td>\n",
       "      <td>4.3906</td>\n",
       "      <td>38.2788</td>\n",
       "      <td>Turdus tephronotus</td>\n",
       "      <td>African Bare-eyed Thrush</td>\n",
       "      <td>Rolf A. de By</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.xeno-canto.org/128013</td>\n",
       "      <td>abethr1/XC128013.ogg</td>\n",
       "      <td>/kaggle/input/birdclef-2023/train_audio_wav/ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abethr1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>-2.9524</td>\n",
       "      <td>38.2921</td>\n",
       "      <td>Turdus tephronotus</td>\n",
       "      <td>African Bare-eyed Thrush</td>\n",
       "      <td>James Bradley</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://www.xeno-canto.org/363501</td>\n",
       "      <td>abethr1/XC363501.ogg</td>\n",
       "      <td>/kaggle/input/birdclef-2023/train_audio_wav/ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  primary_label secondary_labels      type  latitude  longitude  \\\n",
       "0       abethr1               []  ['song']    4.3906    38.2788   \n",
       "1       abethr1               []  ['call']   -2.9524    38.2921   \n",
       "\n",
       "      scientific_name               common_name         author  \\\n",
       "0  Turdus tephronotus  African Bare-eyed Thrush  Rolf A. de By   \n",
       "1  Turdus tephronotus  African Bare-eyed Thrush  James Bradley   \n",
       "\n",
       "                                             license  rating  \\\n",
       "0  Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
       "1  Creative Commons Attribution-NonCommercial-Sha...     3.5   \n",
       "\n",
       "                                 url              filename  \\\n",
       "0  https://www.xeno-canto.org/128013  abethr1/XC128013.ogg   \n",
       "1  https://www.xeno-canto.org/363501  abethr1/XC363501.ogg   \n",
       "\n",
       "                                            filepath  target  \n",
       "0  /kaggle/input/birdclef-2023/train_audio_wav/ab...       0  \n",
       "1  /kaggle/input/birdclef-2023/train_audio_wav/ab...       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{CFG.BASE_PATH}/train_metadata.csv')\n",
    "filename = df.filename.str.replace('.ogg', '.wav')\n",
    "df['filepath'] = CFG.BASE_PATH + '/train_audio_wav/' + filename\n",
    "df['target'] = df.primary_label.map(CFG.name2label)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "df['secondary_labels'] = df['secondary_labels'].apply(ast.literal_eval)\n",
    "df['multi_labels'] = df.apply(lambda row: [row['primary_label']] + row['secondary_labels'], axis=1)\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(df['multi_labels'])\n",
    "df['multi_labels'] = df['multi_labels'].astype(str)\n",
    "df['secondary_labels'] = df['secondary_labels'].astype(str)\n",
    "# pd.options.display.max_rows = 50\n",
    "# df['multi_labels'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize the StratifiedKFold object with 5 splits and shuffle the data\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "# Reset the index of the dataframe\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Create a new column in the dataframe to store the fold number for each row\n",
    "df[\"fold\"] = -1\n",
    "\n",
    "# Iterate over the folds and assign the corresponding fold number to each row in the dataframe\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['primary_label'])):\n",
    "    df.loc[val_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch(batch, row=3, col=3, label2name=None,):\n",
    "    \"\"\"Plot one batch data\"\"\"\n",
    "    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "        audios, tars = batch\n",
    "    else:\n",
    "        audios = batch\n",
    "        tars = None\n",
    "    plt.figure(figsize=(col*5, row*3))\n",
    "    for idx in range(row*col):\n",
    "        ax = plt.subplot(row, col, idx+1)\n",
    "        plt.plot(audios[idx].numpy(), color=cmap(0.1))\n",
    "        if tars is not None:\n",
    "            label = tars[idx].numpy().argmax()\n",
    "            name = label2name[label]\n",
    "            plt.title(name)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_history(history):\n",
    "    \"\"\"Plot trainign history, credit: @cdeotte\"\"\"\n",
    "    epochs = len(history.history['auc'])\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(np.arange(epochs),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n",
    "    plt.plot(np.arange(epochs),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n",
    "    x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n",
    "    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n",
    "    plt.ylabel('AUC (PR)',size=14); plt.xlabel('Epoch',size=14)\n",
    "    plt.legend(loc=2)\n",
    "    plt2 = plt.gca().twinx()\n",
    "    plt2.plot(np.arange(epochs),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n",
    "    plt2.plot(np.arange(epochs),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n",
    "    x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n",
    "    ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n",
    "    plt.ylabel('Loss',size=14)\n",
    "    plt.title('Fold %i - Training Plot'%(fold+1),size=18)\n",
    "    plt.legend(loc=3)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def gc_collect():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_weight(weight):\n",
    "    target_string='model.classifier'\n",
    "    drop_keys = [key for key in weight.keys() if target_string in key]\n",
    "    target_string='att_block'\n",
    "    drop_keys += [key for key in weight.keys() if target_string in key]\n",
    "    for key in drop_keys:\n",
    "        if key in weight:\n",
    "            del weight[key]\n",
    "    return weight\n",
    "\n",
    "def name2onehot(multi_label_names: torch.Tensor):\n",
    "    multi_label_names = [ast.literal_eval(multi_label_name) for multi_label_name in multi_label_names]\n",
    "    multi_label_onehot=mlb.transform(multi_label_names)\n",
    "    multi_label_onehot=torch.tensor(multi_label_onehot).float()\n",
    "    return multi_label_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/multi_label/exp11_secondary_label_no_finetuning/wandb/run-20230504_105859-2erm404c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public/runs/2erm404c\" target=\"_blank\">fold-0|dim-313x224|model-tf_efficientnet_b1_ns|2023-05-04 19:58:58</a></strong> to <a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "#### Training\n",
      "#### Fold: 1 | Image Size: (224, 313) | Model: tf_efficientnet_b1_ns | Batch Size: 128 | Scheduler: cos\n",
      "#### Num Train: 19,627 | Num Valid: 3,381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:40<00:00,  1.04s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.16512264666304766 | Val Loss: 0.00932395892838637 | Val Padded_cmAP : 0.4535156407821005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:38<00:00,  1.03s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.008457746030158036 | Val Loss: 0.00804293997309826 | Val Padded_cmAP : 0.4536388791260058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.006770043089598804 | Val Loss: 0.006942212081479805 | Val Padded_cmAP : 0.45542675047974956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.005941288216136299 | Val Loss: 0.009067254347933663 | Val Padded_cmAP : 0.45665457755213795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.005550863871399265 | Val Loss: 0.012210082590442014 | Val Padded_cmAP : 0.4604327305258013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.03s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 0.0052700462122145415 | Val Loss: 0.0077451532189216875 | Val Padded_cmAP : 0.46761508978796146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 0.005065208697062615 | Val Loss: 0.00564782017910922 | Val Padded_cmAP : 0.4818121275479047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 0.004880450396834836 | Val Loss: 0.006267124062610997 | Val Padded_cmAP : 0.5018918092341763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:38<00:00,  1.03s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss: 0.004727563978015602 | Val Loss: 0.004872225380192201 | Val Padded_cmAP : 0.5253256527920644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:38<00:00,  1.03s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 0.004520547591367519 | Val Loss: 0.004966146045329946 | Val Padded_cmAP : 0.5511339172669497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 0.0043549329124076604 | Val Loss: 0.004522471223026514 | Val Padded_cmAP : 0.5745427014806421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:40<00:00,  1.04s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 0.0041499645993500565 | Val Loss: 0.003939721017593035 | Val Padded_cmAP : 0.6072609097584541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 0.003971588344301109 | Val Loss: 0.003807358391996887 | Val Padded_cmAP : 0.6254191172006882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 0.0037831551480022345 | Val Loss: 0.003581891060565357 | Val Padded_cmAP : 0.6486668711423585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:38<00:00,  1.03s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 0.0036530437933692296 | Val Loss: 0.00346247428872933 | Val Padded_cmAP : 0.6586917806480047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.01s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss: 0.0034706323247330334 | Val Loss: 0.0033776837840883266 | Val Padded_cmAP : 0.6797636323580601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:38<00:00,  1.03s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train Loss: 0.003381474760010258 | Val Loss: 0.003194166994136241 | Val Padded_cmAP : 0.6901967185563302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:39<00:00,  1.03s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train Loss: 0.0032293677644489645 | Val Loss: 0.0030468108080741432 | Val Padded_cmAP : 0.7073880898395475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train Loss: 0.003115365629435166 | Val Loss: 0.003067130059072817 | Val Padded_cmAP : 0.7143914999521863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train Loss: 0.003022252386980146 | Val Loss: 0.0029325209174270706 | Val Padded_cmAP : 0.725921470337229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:30<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train Loss: 0.002888423549434678 | Val Loss: 0.0028961233415261464 | Val Padded_cmAP : 0.7287405474992723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.01s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train Loss: 0.002819674227132716 | Val Loss: 0.0028778586484905747 | Val Padded_cmAP : 0.737961031151341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train Loss: 0.0027384800358687517 | Val Loss: 0.0028394615122427544 | Val Padded_cmAP : 0.7408533249348245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train Loss: 0.0026651139192694386 | Val Loss: 0.0027860126639198926 | Val Padded_cmAP : 0.747038451744066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:39<00:00,  1.03s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Train Loss: 0.0025790330663613683 | Val Loss: 0.002724111860583502 | Val Padded_cmAP : 0.7540619505547006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Train Loss: 0.0025021309371698985 | Val Loss: 0.002701371442526579 | Val Padded_cmAP : 0.7562610683446265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Train Loss: 0.002470214669774105 | Val Loss: 0.002640009680935354 | Val Padded_cmAP : 0.7608488803835864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:38<00:00,  1.03s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Train Loss: 0.0024037552731377737 | Val Loss: 0.0026409251580911653 | Val Padded_cmAP : 0.7627738457289204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:29<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Train Loss: 0.0023408394999342498 | Val Loss: 0.0025779094495293167 | Val Padded_cmAP : 0.7666339997504465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Train Loss: 0.0022969877607394735 | Val Loss: 0.002618726082059934 | Val Padded_cmAP : 0.767286658096985\n",
      "# Loading best model\n",
      "# Infering OOF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:28<00:00,  1.06s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = igetitem(value, i)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> FOLD 1 Primary_Padded_cmAP = 0.817\n",
      "# WandB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb : 100%|██████████| 1124/1124 [01:04<00:00, 17.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3497.443 MB of 3497.443 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▂▄▅▇██████▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁</td></tr><tr><td>num_train</td><td>▁</td></tr><tr><td>num_valid</td><td>▁</td></tr><tr><td>primary_cmAP</td><td>▁</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>▆▅▄▆█▅▃▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_padded_cmAP</td><td>▁▁▁▁▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>loss</td><td>0.00205</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>num_train</td><td>19627</td></tr><tr><td>num_valid</td><td>3381</td></tr><tr><td>primary_cmAP</td><td>0.8167</td></tr><tr><td>train_loss</td><td>0.0023</td></tr><tr><td>valid_loss</td><td>0.00262</td></tr><tr><td>valid_padded_cmAP</td><td>0.76729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fold-0|dim-313x224|model-tf_efficientnet_b1_ns|2023-05-04 19:58:58</strong>: <a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public/runs/2erm404c\" target=\"_blank\">https://wandb.ai/hirokin1999/birdclef-2023-public/runs/2erm404c</a><br/>Synced 5 W&B file(s), 1 media file(s), 1155 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230504_105859-2erm404c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/multi_label/exp11_secondary_label_no_finetuning/wandb/run-20230504_123550-3shf13qj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public/runs/3shf13qj\" target=\"_blank\">fold-1|dim-313x224|model-tf_efficientnet_b1_ns|2023-05-04 19:58:58</a></strong> to <a href=\"https://wandb.ai/hirokin1999/birdclef-2023-public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "#### Training\n",
      "#### Fold: 2 | Image Size: (224, 313) | Model: tf_efficientnet_b1_ns | Batch Size: 128 | Scheduler: cos\n",
      "#### Num Train: 19,629 | Num Valid: 3,382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:40<00:00,  1.04s/it]\n",
      "100%|██████████| 27/27 [00:27<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.15807502705289364 | Val Loss: 0.009141810514308788 | Val Padded_cmAP : 0.45266725736003993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:28<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.008395686703310772 | Val Loss: 0.008042658420486582 | Val Padded_cmAP : 0.45446007251434595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:40<00:00,  1.04s/it]\n",
      "100%|██████████| 27/27 [00:27<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.006712529466596323 | Val Loss: 0.007069339768754112 | Val Padded_cmAP : 0.45493237054796026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:42<00:00,  1.06s/it]\n",
      "100%|██████████| 27/27 [00:27<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.00593717971078858 | Val Loss: 0.006317392215822582 | Val Padded_cmAP : 0.4567048864231868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:27<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.005538328184879252 | Val Loss: 0.005803605731300733 | Val Padded_cmAP : 0.4603897321406846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.01s/it]\n",
      "100%|██████████| 27/27 [00:27<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 0.005284738844841138 | Val Loss: 0.008255868839720884 | Val Padded_cmAP : 0.4678637817735423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:37<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:27<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 0.005096451451929359 | Val Loss: 0.005810164372195248 | Val Padded_cmAP : 0.478032356120023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.02s/it]\n",
      "100%|██████████| 27/27 [00:27<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 0.004934719264773386 | Val Loss: 0.005065653205814737 | Val Padded_cmAP : 0.49668944749276356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [02:36<00:00,  1.02s/it]\n",
      " 30%|██▉       | 8/27 [00:11<00:26,  1.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16489/1807090594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mval_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname2onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7f1e6efe0290> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    }
   ],
   "source": [
    "oof_pred = []; oof_true = []; oof_val = []; oof_ids = []; oof_folds = [] \n",
    "\n",
    "num_classes = CFG.num_classes\n",
    "df = df.copy()\n",
    "for fold in range(CFG.num_fold):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    # Check if the fold is selected\n",
    "    if fold not in CFG.selected_folds:\n",
    "        continue\n",
    "    \n",
    "    # Initialize Weights and Biases\n",
    "    if CFG.wandb:\n",
    "        run = wandb_init(fold)\n",
    "    \n",
    "    # Compute batch size and number of samples to drop\n",
    "    infer_bs = CFG.valid_bs\n",
    "    drop_remainder = CFG.drop_remainder\n",
    "    \n",
    "    # Split dataset with cv filter\n",
    "    if CFG.cv_filter:\n",
    "        df = com.filter_data(df, thr=5)\n",
    "        train_df = df.query(\"fold!=@fold | ~cv\").reset_index(drop=True)\n",
    "        valid_df = df.query(\"fold==@fold & cv\").reset_index(drop=True)\n",
    "    else:\n",
    "        train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "        valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    \n",
    "    # Upsample train data\n",
    "    train_df = com.upsample_data(train_df, thr=CFG.upsample_thr)\n",
    "#     train_df = downsample_data(train_df, thr=500)\n",
    "\n",
    "    # Get file paths and labels\n",
    "    train_paths = train_df.filepath.values; train_labels = train_df.target.values\n",
    "    valid_paths = valid_df.filepath.values; valid_labels = valid_df.target.values\n",
    "\n",
    "    # Shuffle the file paths and labels\n",
    "    index = np.arange(len(train_paths))\n",
    "    np.random.shuffle(index)\n",
    "    train_paths  = train_paths[index]\n",
    "    train_labels = train_labels[index]\n",
    "\n",
    "    # wav\n",
    "    train_ftype = list(map(lambda x: '.wav' in x, train_paths))\n",
    "    valid_ftype = list(map(lambda x: '.wav' in x, valid_paths))\n",
    "\n",
    "    # Compute the number of training and validation samples\n",
    "    num_train = len(train_paths); num_valid = len(valid_paths)\n",
    "        \n",
    "    # Log the number of training and validation samples if Weights and Biases is being used\n",
    "    if CFG.wandb:\n",
    "        wandb.log({'num_train':num_train,\n",
    "                   'num_valid':num_valid})\n",
    "        \n",
    "    # Build the training and validation datasets\n",
    "    # For debugging\n",
    "    if CFG.debug:\n",
    "        min_samples = CFG.batch_size\n",
    "        train_ds = prep.BirdDataset(train_df.iloc[:min_samples], is_train=True)\n",
    "        valid_ds = prep.BirdDataset(valid_df, is_train=False)\n",
    "    else:\n",
    "        train_ds = prep.BirdDataset(train_df, is_train=True)\n",
    "        valid_ds = prep.BirdDataset(valid_df, is_train=False)\n",
    "    # dataloader\n",
    "    train_dataloader, val_dataloader = modeler.make_dataloder(train_ds, valid_ds)\n",
    "    \n",
    "    wav_to_logmel = Wav2Logmel()\n",
    "    # Clear the session and build the model\n",
    "    model = BirdCLEF23Net(num_classes=CFG.num_classes)\n",
    "    # Load birdclef pretrained weights\n",
    "    if CFG.pretrain == True:\n",
    "        weight=torch.load(CFG.pretrained_model_path)\n",
    "        weight=drop_weight(weight)\n",
    "        print('load pre-trained model : ', CFG.pretrained_model_path)\n",
    "        print(model.load_state_dict(weight, strict=False))\n",
    "    model.to(device)\n",
    "    wav_to_logmel.to(device)\n",
    "    \n",
    "    print('#' * 25)\n",
    "    print('#### Training')\n",
    "    print('#### Fold: %i | Image Size: (%i, %i) | Model: %s | Batch Size: %i | Scheduler: %s' %\n",
    "        (fold + 1, *CFG.img_size, CFG.model_name, CFG.batch_size, CFG.scheduler))\n",
    "    print('#### Num Train: {:,} | Num Valid: {:,}'.format(len(train_paths), len(valid_paths)))\n",
    "\n",
    "    optimizer = com.get_optimizer(model)\n",
    "    # TODO com.get_scheduler\n",
    "    scheduler = CosineLRScheduler(optimizer, t_initial=CFG.epochs, lr_min=CFG.lr_min, \n",
    "                                  warmup_t=CFG.warmup_t, warmup_lr_init=CFG.warmup_lr_init, warmup_prefix=True)\n",
    "    criterion = com.get_criterion()\n",
    "\n",
    "    best_score = -1\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(2 if CFG.debug else CFG.epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (inputs, sample_info) in enumerate(tqdm(train_dataloader)):\n",
    "            inputs, targets = inputs.to(device), sample_info['multi_labels']\n",
    "            targets = name2onehot(targets)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logmel = wav_to_logmel(inputs)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs, mix_targets = model(logmel, targets)\n",
    "                loss = modeler.loss_fn(outputs, mix_targets)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            if np.isinf(loss.item()) or np.isnan(loss.item()):\n",
    "                print(f'Bad loss, skipping the batch {batch_idx}')\n",
    "                del loss, outputs, mix_targets\n",
    "                gc_collect()\n",
    "                continue\n",
    "            epoch_loss += loss.item()\n",
    "            # wandb logger (Train loss)\n",
    "            run.log({'loss': loss.item()})\n",
    "        scheduler.step(epoch+1)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, sample_info in tqdm(val_dataloader):\n",
    "                inputs, targets = inputs.to(device), sample_info['multi_labels']\n",
    "                targets = name2onehot(targets)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                logmel = wav_to_logmel(inputs)\n",
    "                outputs = model(logmel)\n",
    "                loss = modeler.loss_fn(outputs, targets)\n",
    "                outputs = outputs[\"clipwise_output\"]#torch.softmax(outputs, dim=1)\n",
    "                #outputs = torch.softmax(outputs, dim=1)\n",
    "                val_loss += loss.item()\n",
    "                val_preds.append(outputs.detach().cpu().numpy())\n",
    "                val_true.append(targets.detach().cpu().numpy())\n",
    "\n",
    "        val_preds = np.vstack(val_preds)\n",
    "        val_true = np.vstack(val_true)\n",
    "        # Metrics\n",
    "        val_score = com.padded_cmap(val_true, val_preds)\n",
    "        # Checkpoint\n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), f'fold-{fold}.pth')\n",
    "            art = wandb.Artifact(\"birdclef-2023\", type=\"model\")\n",
    "            art.add_file(f'fold-{fold}.pth')\n",
    "            run.log_artifact(art)\n",
    "\n",
    "        print(f'Epoch: {epoch + 1} | Train Loss: {epoch_loss / len(train_dataloader)} | '\n",
    "            f'Val Loss: {val_loss / len(val_dataloader)} | Val Padded_cmAP : {val_score}')\n",
    "        \n",
    "        # wandb logger\n",
    "        lr = scheduler.get_epoch_values(epoch)[0]\n",
    "        run.log({'train_loss': epoch_loss / len(train_dataloader),\n",
    "                 'lr': lr,\n",
    "                 'epoch': epoch+1,\n",
    "                 'valid_loss': val_loss / len(val_dataloader),\n",
    "                 'valid_padded_cmAP': val_score,})\n",
    "        \n",
    "        \n",
    "    # Load best checkpoint\n",
    "    print('# Loading best model')\n",
    "    model.load_state_dict(torch.load(f'fold-{fold}.pth'), strict=False)\n",
    "\n",
    "    # Predict on the validation data for oof result\n",
    "    print('# Infering OOF')\n",
    "    model.eval()\n",
    "    oof_pred_ = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, sample_info in tqdm(val_dataloader):\n",
    "            inputs, targets = inputs.to(device), sample_info['multi_labels']\n",
    "            targets = name2onehot(targets)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            logmel = wav_to_logmel(inputs)\n",
    "            outputs = model(logmel)\n",
    "            outputs = outputs[\"clipwise_output\"]#torch.softmax(outputs, dim=1)\n",
    "            oof_pred_.append(outputs.detach().cpu().numpy())\n",
    "            #print(oof_pred_.shape)\n",
    "\n",
    "    oof_pred_ = np.concatenate(oof_pred_, axis=0)\n",
    "    # oof_pred : 5\n",
    "    oof_pred.append(oof_pred_)\n",
    "\n",
    "    # Get ids and targets\n",
    "    oof_true.append(valid_labels)\n",
    "    oof_folds.append(np.ones_like(oof_true[-1], dtype='int8') * fold)\n",
    "    oof_ids.append(valid_paths)\n",
    "\n",
    "    # Save valid data prediction\n",
    "    y_true = np.array(oof_true[-1])\n",
    "    y_pred = np.argmax(oof_pred[-1], axis=-1)\n",
    "    \n",
    "    valid_df['pred'] = y_pred\n",
    "    valid_df['miss'] = y_true != y_pred\n",
    "    valid_df[CFG.class_names] = oof_pred[-1].tolist()\n",
    "    # Log the metrics\n",
    "    scores = {}\n",
    "    cmAP = com.padded_cmap(com.one_hot_encode(y_true), oof_pred[-1])\n",
    "    oof_val.append(best_score)\n",
    "    print('\\n>>> FOLD %i Primary_Padded_cmAP = %.3f' % (fold+1, cmAP))\n",
    "    scores.update({'epoch': best_epoch,\n",
    "                   'primary_cmAP': cmAP,})\n",
    "    # wandb logger \n",
    "    run.log(scores)\n",
    "    # Show training plot\n",
    "    # if CFG.training_plot:\n",
    "    #     plot_history(history)\n",
    "    # Log metrics, media to wandb\n",
    "    if CFG.wandb:\n",
    "        print('# WandB')\n",
    "        log_wandb(valid_df)\n",
    "        wandb.run.finish()\n",
    "        #display(ipd.IFrame(run.url, width=1080, height=720))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(row):\n",
    "    row['filename'] = row['filepath'].split('/',5)[-1]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# OOF Data\n",
    "y_pred = np.concatenate(oof_pred)\n",
    "y_true = np.concatenate(oof_true)\n",
    "ids = np.concatenate(oof_ids)\n",
    "folds = np.concatenate(oof_folds)\n",
    "\n",
    "# Overall cmAP\n",
    "cmAP = com.padded_cmap(com.one_hot_encode(y_true), y_pred)\n",
    "\n",
    "# Overall AUC in PR curve\n",
    "# y_true_one_hot = torch.nn.functional.one_hot(torch.tensor(y_true))\n",
    "# y_pred_tensor = torch.tensor(y_pred)\n",
    "#auc = average_precision_score(y_true_one_hot.numpy(), y_pred_tensor.numpy(), average='macro')\n",
    "\n",
    "print('>>> Overall cmAP: ', cmAP)\n",
    "#print('>>> Overall AUC(PR): ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save OOF data to disk\n",
    "# columns = ['filepath', 'fold', 'true', 'pred', *CFG.class_names]\n",
    "# df_oof = pd.DataFrame(np.concatenate([ids[:,None], folds, y_true,\n",
    "#                                       np.argmax(y_pred,axis=1)[:,None], y_pred], axis=1), columns=columns)\n",
    "# df_oof['class_name'] = df_oof.true.map(CFG.label2name)\n",
    "# df_oof['miss'] = df_oof.true!=df_oof.pred\n",
    "# tqdm.pandas(desc='id ')\n",
    "# df_oof = df_oof.progress_apply(get_id,axis=1)\n",
    "# df_oof.to_csv('oof.csv',index=False)\n",
    "# display(df_oof.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in atexit._run_exitfuncs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1871, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1967, in _on_finish\n",
      "    self._telemetry_imports(tel.imports_finish)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/lib/telemetry.py\", line 41, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 572, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 583, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\", line 74, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_queue.py\", line 49, in _publish\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1882, in _atexit_cleanup\n",
      "    self._backend.cleanup()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/backend/backend.py\", line 246, in cleanup\n",
      "    self.interface.join()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\", line 475, in join\n",
      "    super().join()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 666, in join\n",
      "    _ = self._communicate_shutdown()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\", line 472, in _communicate_shutdown\n",
      "    _ = self._communicate(record)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\", line 226, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\", line 231, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n"
     ]
    }
   ],
   "source": [
    "# print('Miss Total:')\n",
    "# display(df_oof.query(\"miss==True\").shape[0])\n",
    "\n",
    "# print()\n",
    "# print('Miss Distribution Top10:')\n",
    "# display(df_oof.query(\"miss==True\").class_name.value_counts()[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
