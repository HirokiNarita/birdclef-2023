#########################
#### Training
#### Fold: 2 | Image Size: (224, 313) | Model: tf_efficientnet_b1_ns | Batch Size: 128 | Scheduler: cos
#### Num Train: 19,629 | Num Valid: 3,382





































































100%|██████████| 154/154 [02:23<00:00,  1.07it/s]








 96%|█████████▋| 26/27 [00:18<00:00,  2.01it/s]
100%|██████████| 27/27 [00:19<00:00,  1.41it/s]






































































100%|██████████| 154/154 [02:23<00:00,  1.08it/s]









100%|██████████| 27/27 [00:19<00:00,  1.40it/s]
Epoch: 2 | Train Loss: 0.006583042494202783 | Val Loss: 0.007310162833029473 | Val Padded_cmAP : 0.48011819496874203






































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








 96%|█████████▋| 26/27 [00:18<00:00,  2.01it/s]
100%|██████████| 27/27 [00:19<00:00,  1.42it/s]





































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]









100%|██████████| 27/27 [00:19<00:00,  1.39it/s]
Epoch: 4 | Train Loss: 0.00463299890798698 | Val Loss: 0.005676031785292758 | Val Padded_cmAP : 0.4814134314507909






































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








100%|██████████| 27/27 [00:18<00:00,  1.44it/s]
Epoch: 5 | Train Loss: 0.004266381094401533 | Val Loss: 0.005338854208174679 | Val Padded_cmAP : 0.48288193618642156






































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








100%|██████████| 27/27 [00:18<00:00,  1.44it/s]
Epoch: 6 | Train Loss: 0.004059468621279222 | Val Loss: 0.005160772396872441 | Val Padded_cmAP : 0.4877104055987997





































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








100%|██████████| 27/27 [00:19<00:00,  1.37it/s]
  0%|          | 0/154 [00:00<?, ?it/s]






































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








 93%|█████████▎| 25/27 [00:17<00:01,  1.93it/s]
100%|██████████| 27/27 [00:18<00:00,  1.47it/s]





































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]









100%|██████████| 27/27 [00:19<00:00,  1.39it/s]
Epoch: 9 | Train Loss: 0.0037384749777228028 | Val Loss: 0.004602272434298087 | Val Padded_cmAP : 0.5168667880465785






































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








100%|██████████| 27/27 [00:19<00:00,  1.41it/s]
Epoch: 10 | Train Loss: 0.0036338499124319136 | Val Loss: 0.004241735338129931 | Val Padded_cmAP : 0.5371666722083133





































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








100%|██████████| 27/27 [00:18<00:00,  2.36it/s]
100%|██████████| 27/27 [00:18<00:00,  1.44it/s]





































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








100%|██████████| 27/27 [00:18<00:00,  1.43it/s]
  0%|          | 0/154 [00:00<?, ?it/s]





































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








100%|██████████| 27/27 [00:18<00:00,  1.44it/s]
  0%|          | 0/154 [00:00<?, ?it/s]





































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








100%|██████████| 27/27 [00:18<00:00,  1.43it/s]
  0%|          | 0/154 [00:00<?, ?it/s]






































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








100%|██████████| 27/27 [00:18<00:00,  1.44it/s]
Epoch: 15 | Train Loss: 0.0030915532427440795 | Val Loss: 0.0033981075027474652 | Val Padded_cmAP : 0.6535313038126519





































































100%|██████████| 154/154 [02:22<00:00,  1.08it/s]








100%|██████████| 27/27 [00:19<00:00,  1.42it/s]
  0%|          | 0/154 [00:00<?, ?it/s]





















 30%|██▉       | 46/154 [00:45<01:41,  1.07it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f46ed7cb320>
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1510, in __del__
    self._shutdown_workers()
  File "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1474, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/conda/lib/python3.7/multiprocessing/process.py", line 140, in join
    res = self._popen.wait(timeout)
  File "/opt/conda/lib/python3.7/multiprocessing/popen_fork.py", line 45, in wait
    if not wait([self.sentinel], timeout):
  File "/opt/conda/lib/python3.7/multiprocessing/connection.py", line 921, in wait
    ready = selector.select(timeout)
  File "/opt/conda/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
  File "/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 23426) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
 30%|██▉       | 46/154 [00:46<01:48,  1.01s/it]
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 152, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 138, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 405, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 170, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 127, in communicate_stop_status
    resp = self._communicate_stop_status(status)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 395, in _communicate_stop_status
    resp = self._communicate(req, local=True)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
