
  0%|          | 0/316 [00:00<?, ?it/s]
load pre-trained model :  /kaggle/working/multi_label/exp22_primary_label_2022_1st_like/fold-0.pth
<All keys matched successfully>
#########################
#### Training
#### Fold: 1 | Image Size: (128, 1001) | Model: tf_efficientnet_b1_ns | Batch Size: 64 | Scheduler: cos

































































































































































100%|██████████| 316/316 [05:58<00:00,  1.14s/it]









 93%|█████████▎| 25/27 [00:22<00:01,  1.38it/s]
100%|██████████| 27/27 [00:23<00:00,  1.13it/s]







































































































































































100%|██████████| 316/316 [05:53<00:00,  1.12s/it]










 93%|█████████▎| 25/27 [00:22<00:01,  1.36it/s]
100%|██████████| 27/27 [00:23<00:00,  1.14it/s]

































































































































































100%|██████████| 316/316 [05:44<00:00,  1.09s/it]










100%|██████████| 27/27 [00:23<00:00,  1.14it/s]
  0%|          | 0/316 [00:00<?, ?it/s]































































































































































100%|██████████| 316/316 [05:36<00:00,  1.07s/it]










100%|██████████| 27/27 [00:23<00:00,  1.15it/s]
Epoch: 4 | Train Loss: 0.3085898441981666 | Val Loss: 0.29904623412423664 | Val Padded_cmAP : 0.8973638877637886
































































































































































100%|██████████| 316/316 [05:36<00:00,  1.06s/it]










100%|██████████| 27/27 [00:23<00:00,  1.13it/s]
Epoch: 5 | Train Loss: 0.30195995632417594 | Val Loss: 0.28254000649408056 | Val Padded_cmAP : 0.8997657631308397






























































































































































100%|██████████| 316/316 [05:34<00:00,  1.06s/it]










 96%|█████████▋| 26/27 [00:23<00:00,  1.38it/s]
100%|██████████| 27/27 [00:23<00:00,  1.14it/s]
























































































































































100%|██████████| 316/316 [05:27<00:00,  1.04s/it]









100%|██████████| 27/27 [00:23<00:00,  1.14it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


























































































































































100%|██████████| 316/316 [05:31<00:00,  1.05s/it]









100%|██████████| 27/27 [00:23<00:00,  1.15it/s]
  0%|          | 0/316 [00:00<?, ?it/s]





























































































































































100%|██████████| 316/316 [05:32<00:00,  1.05s/it]









100%|██████████| 27/27 [00:23<00:00,  1.15it/s]
  0%|          | 0/316 [00:00<?, ?it/s]

































































































































































100%|██████████| 316/316 [05:37<00:00,  1.07s/it]










100%|██████████| 27/27 [00:23<00:00,  1.14it/s]
  0%|          | 0/316 [00:00<?, ?it/s]






























































































































































100%|██████████| 316/316 [05:30<00:00,  1.05s/it]










100%|██████████| 27/27 [00:23<00:00,  1.14it/s]
  0%|          | 0/316 [00:00<?, ?it/s]


































































































































































100%|██████████| 316/316 [05:37<00:00,  1.07s/it]










100%|██████████| 27/27 [00:23<00:00,  1.15it/s]
Epoch: 12 | Train Loss: 0.27941656914315643 | Val Loss: 0.296011607128161 | Val Padded_cmAP : 0.9009352344302034


































































































































































100%|██████████| 316/316 [05:51<00:00,  1.11s/it]










 96%|█████████▋| 26/27 [00:23<00:00,  1.39it/s]
100%|██████████| 27/27 [00:23<00:00,  1.14it/s]






























































































































































100%|██████████| 316/316 [05:42<00:00,  1.08s/it]










100%|██████████| 27/27 [00:23<00:00,  1.15it/s]
Epoch: 14 | Train Loss: 0.27252998207754725 | Val Loss: 0.30232333253931115 | Val Padded_cmAP : 0.9015065228787932










































































































 63%|██████▎   | 200/316 [03:51<02:14,  1.16s/it]
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 152, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 138, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 405, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
